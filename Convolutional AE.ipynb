{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/gpu:2'):\n",
    "#     from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D,Flatten,Reshape\n",
    "#     from keras.models import Model\n",
    "#     from keras import backend as K\n",
    "\n",
    "#     input_img = Input(shape=(64, 64,1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "#     x = Conv2D(64, (64, 64), activation='relu', padding='same')(input_img)\n",
    "#     x = Conv2D(1, (64, 64), activation='relu', padding='same')(x)\n",
    "#     x = Flatten()(x)\n",
    "\n",
    "#     x = Dense(4096, activation='relu')(x)\n",
    "#     x = Dense(1024, activation='relu')(x)\n",
    "#     encoded = Dense(128, activation='relu')(x)\n",
    "\n",
    "#     x = Dense(1024, activation='relu')(encoded)\n",
    "#     x = Dense(4096, activation='relu')(x)\n",
    "\n",
    "#     x = Reshape((64,64,1))(x)\n",
    "#     x = UpSampling2D((8,8))(x)\n",
    "#     x = Reshape((64,64,64))(x)\n",
    "#     x = Conv2D(64, (64, 64), activation='relu', padding='same')(x)\n",
    "#     decoded = Conv2D(1, (64, 64), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "\n",
    "#     autoencoder = Model(input_img, decoded)\n",
    "#     autoencoder.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(num, data):\n",
    "\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14072, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "# seq = [str(i).zfill(4) for i in range(1,101)]\n",
    "# for s in seq:\n",
    "# for file in glob.glob('GSCdata/*png'):\n",
    "#     images.append(cv2.imread(file,0))\n",
    "images = [cv2.imread(file,0) for file in glob.glob('GSCdata/*png')]\n",
    "names = [re.sub('\\.png$', '',os.path.basename(x)) for x in glob.glob('GSCdata/*png')]\n",
    "images = np.array(images)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11257, 64, 64)\n",
      "(2815, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train, x_test,names_train,names_test = train_test_split(images,names, test_size=0.2)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "images = images.astype('float32') / 255.\n",
    "x_train = x_train.reshape((-1,64,64,1))\n",
    "x_test = x_test.reshape((-1,64,64,1))\n",
    "images = images.reshape((-1,64,64,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "inputs_ = tf.placeholder(tf.float32, (None, 64, 64, 1), name='inputs')\n",
    "targets_ = tf.placeholder(tf.float32, (None, 64, 64, 1), name='targets')\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=inputs_, filters=64, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n",
    "conv2 = tf.layers.conv2d(inputs=conv1, filters=1, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n",
    "\n",
    "flatten1 = tf.reshape(conv2, [-1, 64 * 64])\n",
    "\n",
    "dense1 = tf.layers.dense(inputs=flatten1, units=4096, activation=tf.nn.relu)\n",
    "dense2 = tf.layers.dense(inputs=dense1, units=1024, activation=tf.nn.relu)\n",
    "encoded = tf.layers.dense(inputs=dense2, units=128, activation=tf.nn.sigmoid)\n",
    "\n",
    "flatten2 = tf.reshape(conv2, [-1,64,64,1])\n",
    "upsample1 = tf.image.resize_images(flatten2, size=(64,64), method=tf.image.ResizeMethod.BICUBIC)\n",
    "\n",
    "deconv1 = tf.layers.conv2d_transpose(inputs=upsample1, filters=1, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n",
    "deconv2 = tf.layers.conv2d_transpose(inputs=deconv1, filters=64, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n",
    "\n",
    "logits = tf.layers.conv2d(inputs=deconv2, filters=1, kernel_size=(3,3), padding='same', activation=None)\n",
    "\n",
    "decoded = tf.nn.sigmoid(logits)\n",
    "\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=targets_, logits=logits)\n",
    "\n",
    "cost = tf.reduce_mean(loss)\n",
    "opt = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs_: Tensor(\"inputs:0\", shape=(?, 64, 64, 1), dtype=float32)\n",
      "targets_: Tensor(\"targets:0\", shape=(?, 64, 64, 1), dtype=float32)\n",
      "conv1: Tensor(\"conv2d/Relu:0\", shape=(?, 64, 64, 64), dtype=float32)\n",
      "conv2: Tensor(\"conv2d_1/Relu:0\", shape=(?, 64, 64, 1), dtype=float32)\n",
      "flatten1: Tensor(\"Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "dense1: Tensor(\"dense/Relu:0\", shape=(?, 4096), dtype=float32)\n",
      "dense2: Tensor(\"dense_1/Relu:0\", shape=(?, 1024), dtype=float32)\n",
      "encoded: Tensor(\"dense_2/Sigmoid:0\", shape=(?, 128), dtype=float32)\n",
      "flatten2: Tensor(\"Reshape_1:0\", shape=(?, 64, 64, 1), dtype=float32)\n",
      "upsample1: Tensor(\"Reshape_1:0\", shape=(?, 64, 64, 1), dtype=float32)\n",
      "deconv1: Tensor(\"conv2d_transpose/Relu:0\", shape=(?, 64, 64, 1), dtype=float32)\n",
      "deconv2: Tensor(\"conv2d_transpose_1/Relu:0\", shape=(?, 64, 64, 64), dtype=float32)\n",
      "logits: Tensor(\"conv2d_2/BiasAdd:0\", shape=(?, 64, 64, 1), dtype=float32)\n",
      "decoded: Tensor(\"Sigmoid:0\", shape=(?, 64, 64, 1), dtype=float32)\n",
      "loss: Tensor(\"logistic_loss:0\", shape=(?, 64, 64, 1), dtype=float32)\n",
      "cost: Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.ops.variables import Variable\n",
    "\n",
    "for k, v in locals().items():\n",
    "    if type(v) is Variable or type(v) is tf.Tensor:\n",
    "        print(\"{0}: {1}\".format(k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100... Training loss: 0.6931\n",
      "Epoch: 1/100... Training loss: 0.6900\n",
      "Epoch: 1/100... Training loss: 0.6873\n",
      "Epoch: 1/100... Training loss: 0.6841\n",
      "Epoch: 1/100... Training loss: 0.6804\n",
      "Epoch: 1/100... Training loss: 0.6762\n",
      "Epoch: 1/100... Training loss: 0.6718\n",
      "Epoch: 1/100... Training loss: 0.6671\n",
      "Epoch: 1/100... Training loss: 0.6619\n",
      "Epoch: 1/100... Training loss: 0.6563\n",
      "Epoch: 1/100... Training loss: 0.6503\n",
      "Epoch: 1/100... Training loss: 0.6439\n",
      "Epoch: 1/100... Training loss: 0.6368\n",
      "Epoch: 1/100... Training loss: 0.6293\n",
      "Epoch: 1/100... Training loss: 0.6218\n",
      "Epoch: 1/100... Training loss: 0.6132\n",
      "Epoch: 1/100... Training loss: 0.6046\n",
      "Epoch: 1/100... Training loss: 0.5958\n",
      "Epoch: 1/100... Training loss: 0.5861\n",
      "Epoch: 1/100... Training loss: 0.5762\n",
      "Epoch: 1/100... Training loss: 0.5656\n",
      "Epoch: 2/100... Training loss: 0.5545\n",
      "Epoch: 2/100... Training loss: 0.5427\n",
      "Epoch: 2/100... Training loss: 0.5305\n",
      "Epoch: 2/100... Training loss: 0.5189\n",
      "Epoch: 2/100... Training loss: 0.5058\n",
      "Epoch: 2/100... Training loss: 0.4921\n",
      "Epoch: 2/100... Training loss: 0.4786\n",
      "Epoch: 2/100... Training loss: 0.4645\n",
      "Epoch: 2/100... Training loss: 0.4503\n",
      "Epoch: 2/100... Training loss: 0.4361\n",
      "Epoch: 2/100... Training loss: 0.4217\n",
      "Epoch: 2/100... Training loss: 0.4076\n",
      "Epoch: 2/100... Training loss: 0.3924\n",
      "Epoch: 2/100... Training loss: 0.3854\n",
      "Epoch: 2/100... Training loss: 0.3673\n",
      "Epoch: 2/100... Training loss: 0.3515\n",
      "Epoch: 2/100... Training loss: 0.3403\n",
      "Epoch: 2/100... Training loss: 0.3281\n",
      "Epoch: 2/100... Training loss: 0.3161\n",
      "Epoch: 2/100... Training loss: 0.3044\n",
      "Epoch: 2/100... Training loss: 0.2944\n",
      "Epoch: 3/100... Training loss: 0.2844\n",
      "Epoch: 3/100... Training loss: 0.2750\n",
      "Epoch: 3/100... Training loss: 0.2657\n",
      "Epoch: 3/100... Training loss: 0.2591\n",
      "Epoch: 3/100... Training loss: 0.2510\n",
      "Epoch: 3/100... Training loss: 0.2437\n",
      "Epoch: 3/100... Training loss: 0.2504\n",
      "Epoch: 3/100... Training loss: 0.2323\n",
      "Epoch: 3/100... Training loss: 0.2255\n",
      "Epoch: 3/100... Training loss: 0.2251\n",
      "Epoch: 3/100... Training loss: 0.2234\n",
      "Epoch: 3/100... Training loss: 0.2240\n",
      "Epoch: 3/100... Training loss: 0.2200\n",
      "Epoch: 3/100... Training loss: 0.2177\n",
      "Epoch: 3/100... Training loss: 0.2179\n",
      "Epoch: 3/100... Training loss: 0.2207\n",
      "Epoch: 3/100... Training loss: 0.2179\n",
      "Epoch: 3/100... Training loss: 0.2183\n",
      "Epoch: 3/100... Training loss: 0.2142\n",
      "Epoch: 3/100... Training loss: 0.2115\n",
      "Epoch: 3/100... Training loss: 0.2128\n",
      "Epoch: 4/100... Training loss: 0.2121\n",
      "Epoch: 4/100... Training loss: 0.2090\n",
      "Epoch: 4/100... Training loss: 0.2098\n",
      "Epoch: 4/100... Training loss: 0.2032\n",
      "Epoch: 4/100... Training loss: 0.2043\n",
      "Epoch: 4/100... Training loss: 0.2014\n",
      "Epoch: 4/100... Training loss: 0.1988\n",
      "Epoch: 4/100... Training loss: 0.1990\n",
      "Epoch: 4/100... Training loss: 0.1905\n",
      "Epoch: 4/100... Training loss: 0.1901\n",
      "Epoch: 4/100... Training loss: 0.1878\n",
      "Epoch: 4/100... Training loss: 0.2335\n",
      "Epoch: 4/100... Training loss: 0.1870\n",
      "Epoch: 4/100... Training loss: 0.1857\n",
      "Epoch: 4/100... Training loss: 0.1903\n",
      "Epoch: 4/100... Training loss: 0.1891\n",
      "Epoch: 4/100... Training loss: 0.1870\n",
      "Epoch: 4/100... Training loss: 0.1909\n",
      "Epoch: 4/100... Training loss: 0.1879\n",
      "Epoch: 4/100... Training loss: 0.1879\n",
      "Epoch: 4/100... Training loss: 0.1844\n",
      "Epoch: 5/100... Training loss: 0.1870\n",
      "Epoch: 5/100... Training loss: 0.1849\n",
      "Epoch: 5/100... Training loss: 0.1805\n",
      "Epoch: 5/100... Training loss: 0.1806\n",
      "Epoch: 5/100... Training loss: 0.1786\n",
      "Epoch: 5/100... Training loss: 0.1783\n",
      "Epoch: 5/100... Training loss: 0.1720\n",
      "Epoch: 5/100... Training loss: 0.1706\n",
      "Epoch: 5/100... Training loss: 0.1642\n",
      "Epoch: 5/100... Training loss: 0.1615\n",
      "Epoch: 5/100... Training loss: 0.1612\n",
      "Epoch: 5/100... Training loss: 0.1598\n",
      "Epoch: 5/100... Training loss: 0.1534\n",
      "Epoch: 5/100... Training loss: 0.2262\n",
      "Epoch: 5/100... Training loss: 0.1507\n",
      "Epoch: 5/100... Training loss: 0.1554\n",
      "Epoch: 5/100... Training loss: 0.1565\n",
      "Epoch: 5/100... Training loss: 0.1582\n",
      "Epoch: 5/100... Training loss: 0.1610\n",
      "Epoch: 5/100... Training loss: 0.1640\n",
      "Epoch: 5/100... Training loss: 0.1643\n",
      "Epoch: 6/100... Training loss: 0.1685\n",
      "Epoch: 6/100... Training loss: 0.1713\n",
      "Epoch: 6/100... Training loss: 0.1704\n",
      "Epoch: 6/100... Training loss: 0.1641\n",
      "Epoch: 6/100... Training loss: 0.1644\n",
      "Epoch: 6/100... Training loss: 0.1614\n",
      "Epoch: 6/100... Training loss: 0.1567\n",
      "Epoch: 6/100... Training loss: 0.1532\n",
      "Epoch: 6/100... Training loss: 0.1460\n",
      "Epoch: 6/100... Training loss: 0.1427\n",
      "Epoch: 6/100... Training loss: 0.1408\n",
      "Epoch: 6/100... Training loss: 0.1353\n",
      "Epoch: 6/100... Training loss: 0.1319\n",
      "Epoch: 6/100... Training loss: 0.1307\n",
      "Epoch: 6/100... Training loss: 0.1280\n",
      "Epoch: 6/100... Training loss: 0.1290\n",
      "Epoch: 6/100... Training loss: 0.1239\n",
      "Epoch: 6/100... Training loss: 0.1251\n",
      "Epoch: 6/100... Training loss: 0.1241\n",
      "Epoch: 6/100... Training loss: 0.1224\n",
      "Epoch: 6/100... Training loss: 0.1229\n",
      "Epoch: 7/100... Training loss: 0.1183\n",
      "Epoch: 7/100... Training loss: 0.1135\n",
      "Epoch: 7/100... Training loss: 0.1137\n",
      "Epoch: 7/100... Training loss: 0.1154\n",
      "Epoch: 7/100... Training loss: 0.1145\n",
      "Epoch: 7/100... Training loss: 0.1157\n",
      "Epoch: 7/100... Training loss: 0.1137\n",
      "Epoch: 7/100... Training loss: 0.1150\n",
      "Epoch: 7/100... Training loss: 0.1147\n",
      "Epoch: 7/100... Training loss: 0.1121\n",
      "Epoch: 7/100... Training loss: 0.1135\n",
      "Epoch: 7/100... Training loss: 0.1121\n",
      "Epoch: 7/100... Training loss: 0.1110\n",
      "Epoch: 7/100... Training loss: 0.1085\n",
      "Epoch: 7/100... Training loss: 0.1084\n",
      "Epoch: 7/100... Training loss: 0.1034\n",
      "Epoch: 7/100... Training loss: 0.1035\n",
      "Epoch: 7/100... Training loss: 0.1024\n",
      "Epoch: 7/100... Training loss: 0.1000\n",
      "Epoch: 7/100... Training loss: 0.0981\n",
      "Epoch: 7/100... Training loss: 0.0981\n",
      "Epoch: 8/100... Training loss: 0.0956\n",
      "Epoch: 8/100... Training loss: 0.0951\n",
      "Epoch: 8/100... Training loss: 0.0936\n",
      "Epoch: 8/100... Training loss: 0.0929\n",
      "Epoch: 8/100... Training loss: 0.0933\n",
      "Epoch: 8/100... Training loss: 0.0926\n",
      "Epoch: 8/100... Training loss: 0.0926\n",
      "Epoch: 8/100... Training loss: 0.0915\n",
      "Epoch: 8/100... Training loss: 0.0894\n",
      "Epoch: 8/100... Training loss: 0.0885\n",
      "Epoch: 8/100... Training loss: 0.0903\n",
      "Epoch: 8/100... Training loss: 0.0883\n",
      "Epoch: 8/100... Training loss: 0.0880\n",
      "Epoch: 8/100... Training loss: 0.0865\n",
      "Epoch: 8/100... Training loss: 0.0853\n",
      "Epoch: 8/100... Training loss: 0.0836\n",
      "Epoch: 8/100... Training loss: 0.0849\n",
      "Epoch: 8/100... Training loss: 0.0847\n",
      "Epoch: 8/100... Training loss: 0.0841\n",
      "Epoch: 8/100... Training loss: 0.0837\n",
      "Epoch: 8/100... Training loss: 0.0825\n",
      "Epoch: 9/100... Training loss: 0.0819\n",
      "Epoch: 9/100... Training loss: 0.0817\n",
      "Epoch: 9/100... Training loss: 0.0821\n",
      "Epoch: 9/100... Training loss: 0.0832\n",
      "Epoch: 9/100... Training loss: 0.0814\n",
      "Epoch: 9/100... Training loss: 0.0813\n",
      "Epoch: 9/100... Training loss: 0.0803\n",
      "Epoch: 9/100... Training loss: 0.0790\n",
      "Epoch: 9/100... Training loss: 0.0792\n",
      "Epoch: 9/100... Training loss: 0.0787\n",
      "Epoch: 9/100... Training loss: 0.0795\n",
      "Epoch: 9/100... Training loss: 0.0772\n",
      "Epoch: 9/100... Training loss: 0.0783\n",
      "Epoch: 9/100... Training loss: 0.0785\n",
      "Epoch: 9/100... Training loss: 0.0777\n",
      "Epoch: 9/100... Training loss: 0.0770\n",
      "Epoch: 9/100... Training loss: 0.0770\n",
      "Epoch: 9/100... Training loss: 0.0779\n",
      "Epoch: 9/100... Training loss: 0.0772\n",
      "Epoch: 9/100... Training loss: 0.0764\n",
      "Epoch: 9/100... Training loss: 0.0768\n",
      "Epoch: 10/100... Training loss: 0.0760\n",
      "Epoch: 10/100... Training loss: 0.0766\n",
      "Epoch: 10/100... Training loss: 0.0761\n",
      "Epoch: 10/100... Training loss: 0.0756\n",
      "Epoch: 10/100... Training loss: 0.0766\n",
      "Epoch: 10/100... Training loss: 0.0756\n",
      "Epoch: 10/100... Training loss: 0.0762\n",
      "Epoch: 10/100... Training loss: 0.0740\n",
      "Epoch: 10/100... Training loss: 0.0751\n",
      "Epoch: 10/100... Training loss: 0.0748\n",
      "Epoch: 10/100... Training loss: 0.0751\n",
      "Epoch: 10/100... Training loss: 0.0752\n",
      "Epoch: 10/100... Training loss: 0.0739\n",
      "Epoch: 10/100... Training loss: 0.0746\n",
      "Epoch: 10/100... Training loss: 0.0737\n",
      "Epoch: 10/100... Training loss: 0.0737\n",
      "Epoch: 10/100... Training loss: 0.0739\n",
      "Epoch: 10/100... Training loss: 0.0734\n",
      "Epoch: 10/100... Training loss: 0.0748\n",
      "Epoch: 10/100... Training loss: 0.0731\n",
      "Epoch: 10/100... Training loss: 0.0733\n",
      "Epoch: 11/100... Training loss: 0.0735\n",
      "Epoch: 11/100... Training loss: 0.0722\n",
      "Epoch: 11/100... Training loss: 0.0724\n",
      "Epoch: 11/100... Training loss: 0.0734\n",
      "Epoch: 11/100... Training loss: 0.0735\n",
      "Epoch: 11/100... Training loss: 0.0721\n",
      "Epoch: 11/100... Training loss: 0.0723\n",
      "Epoch: 11/100... Training loss: 0.0719\n",
      "Epoch: 11/100... Training loss: 0.0722\n",
      "Epoch: 11/100... Training loss: 0.0722\n",
      "Epoch: 11/100... Training loss: 0.0725\n",
      "Epoch: 11/100... Training loss: 0.0732\n",
      "Epoch: 11/100... Training loss: 0.0718\n",
      "Epoch: 11/100... Training loss: 0.0719\n",
      "Epoch: 11/100... Training loss: 0.0726\n",
      "Epoch: 11/100... Training loss: 0.0727\n",
      "Epoch: 11/100... Training loss: 0.0705\n",
      "Epoch: 11/100... Training loss: 0.0713\n",
      "Epoch: 11/100... Training loss: 0.0706\n",
      "Epoch: 11/100... Training loss: 0.0718\n",
      "Epoch: 11/100... Training loss: 0.0709\n",
      "Epoch: 12/100... Training loss: 0.0720\n",
      "Epoch: 12/100... Training loss: 0.0719\n",
      "Epoch: 12/100... Training loss: 0.0715\n",
      "Epoch: 12/100... Training loss: 0.0716\n",
      "Epoch: 12/100... Training loss: 0.0711\n",
      "Epoch: 12/100... Training loss: 0.0703\n",
      "Epoch: 12/100... Training loss: 0.0708\n",
      "Epoch: 12/100... Training loss: 0.0703\n",
      "Epoch: 12/100... Training loss: 0.0720\n",
      "Epoch: 12/100... Training loss: 0.0712\n",
      "Epoch: 12/100... Training loss: 0.0711\n",
      "Epoch: 12/100... Training loss: 0.0703\n",
      "Epoch: 12/100... Training loss: 0.0696\n",
      "Epoch: 12/100... Training loss: 0.0705\n",
      "Epoch: 12/100... Training loss: 0.0698\n",
      "Epoch: 12/100... Training loss: 0.0702\n",
      "Epoch: 12/100... Training loss: 0.0694\n",
      "Epoch: 12/100... Training loss: 0.0718\n",
      "Epoch: 12/100... Training loss: 0.0702\n",
      "Epoch: 12/100... Training loss: 0.0701\n",
      "Epoch: 12/100... Training loss: 0.0693\n",
      "Epoch: 13/100... Training loss: 0.0686\n",
      "Epoch: 13/100... Training loss: 0.0692\n",
      "Epoch: 13/100... Training loss: 0.0694\n",
      "Epoch: 13/100... Training loss: 0.0695\n",
      "Epoch: 13/100... Training loss: 0.0690\n",
      "Epoch: 13/100... Training loss: 0.0700\n",
      "Epoch: 13/100... Training loss: 0.0690\n",
      "Epoch: 13/100... Training loss: 0.0696\n",
      "Epoch: 13/100... Training loss: 0.0693\n",
      "Epoch: 13/100... Training loss: 0.0684\n",
      "Epoch: 13/100... Training loss: 0.0705\n",
      "Epoch: 13/100... Training loss: 0.0690\n",
      "Epoch: 13/100... Training loss: 0.0688\n",
      "Epoch: 13/100... Training loss: 0.0676\n",
      "Epoch: 13/100... Training loss: 0.0687\n",
      "Epoch: 13/100... Training loss: 0.0679\n",
      "Epoch: 13/100... Training loss: 0.0680\n",
      "Epoch: 13/100... Training loss: 0.0681\n",
      "Epoch: 13/100... Training loss: 0.0686\n",
      "Epoch: 13/100... Training loss: 0.0672\n",
      "Epoch: 13/100... Training loss: 0.0691\n",
      "Epoch: 14/100... Training loss: 0.0672\n",
      "Epoch: 14/100... Training loss: 0.0684\n",
      "Epoch: 14/100... Training loss: 0.0672\n",
      "Epoch: 14/100... Training loss: 0.0678\n",
      "Epoch: 14/100... Training loss: 0.0680\n",
      "Epoch: 14/100... Training loss: 0.0673\n",
      "Epoch: 14/100... Training loss: 0.0672\n",
      "Epoch: 14/100... Training loss: 0.0679\n",
      "Epoch: 14/100... Training loss: 0.0671\n",
      "Epoch: 14/100... Training loss: 0.0671\n",
      "Epoch: 14/100... Training loss: 0.0673\n",
      "Epoch: 14/100... Training loss: 0.0673\n",
      "Epoch: 14/100... Training loss: 0.0674\n",
      "Epoch: 14/100... Training loss: 0.0671\n",
      "Epoch: 14/100... Training loss: 0.0661\n",
      "Epoch: 14/100... Training loss: 0.0679\n",
      "Epoch: 14/100... Training loss: 0.0662\n",
      "Epoch: 14/100... Training loss: 0.0677\n",
      "Epoch: 14/100... Training loss: 0.0668\n",
      "Epoch: 14/100... Training loss: 0.0675\n",
      "Epoch: 14/100... Training loss: 0.0664\n",
      "Epoch: 15/100... Training loss: 0.0672\n",
      "Epoch: 15/100... Training loss: 0.0660\n",
      "Epoch: 15/100... Training loss: 0.0662\n",
      "Epoch: 15/100... Training loss: 0.0658\n",
      "Epoch: 15/100... Training loss: 0.0659\n",
      "Epoch: 15/100... Training loss: 0.0656\n",
      "Epoch: 15/100... Training loss: 0.0660\n",
      "Epoch: 15/100... Training loss: 0.0663\n",
      "Epoch: 15/100... Training loss: 0.0656\n",
      "Epoch: 15/100... Training loss: 0.0666\n",
      "Epoch: 15/100... Training loss: 0.0657\n",
      "Epoch: 15/100... Training loss: 0.0655\n",
      "Epoch: 15/100... Training loss: 0.0666\n",
      "Epoch: 15/100... Training loss: 0.0640\n",
      "Epoch: 15/100... Training loss: 0.0648\n",
      "Epoch: 15/100... Training loss: 0.0652\n",
      "Epoch: 15/100... Training loss: 0.0663\n",
      "Epoch: 15/100... Training loss: 0.0663\n",
      "Epoch: 15/100... Training loss: 0.0649\n",
      "Epoch: 15/100... Training loss: 0.0648\n",
      "Epoch: 15/100... Training loss: 0.0639\n",
      "Epoch: 16/100... Training loss: 0.0649\n",
      "Epoch: 16/100... Training loss: 0.0643\n",
      "Epoch: 16/100... Training loss: 0.0651\n",
      "Epoch: 16/100... Training loss: 0.0656\n",
      "Epoch: 16/100... Training loss: 0.0645\n",
      "Epoch: 16/100... Training loss: 0.0644\n",
      "Epoch: 16/100... Training loss: 0.0649\n",
      "Epoch: 16/100... Training loss: 0.0645\n",
      "Epoch: 16/100... Training loss: 0.0638\n",
      "Epoch: 16/100... Training loss: 0.0644\n",
      "Epoch: 16/100... Training loss: 0.0641\n",
      "Epoch: 16/100... Training loss: 0.0641\n",
      "Epoch: 16/100... Training loss: 0.0640\n",
      "Epoch: 16/100... Training loss: 0.0641\n",
      "Epoch: 16/100... Training loss: 0.0635\n",
      "Epoch: 16/100... Training loss: 0.0631\n",
      "Epoch: 16/100... Training loss: 0.0637\n",
      "Epoch: 16/100... Training loss: 0.0640\n",
      "Epoch: 16/100... Training loss: 0.0642\n",
      "Epoch: 16/100... Training loss: 0.0632\n",
      "Epoch: 16/100... Training loss: 0.0645\n",
      "Epoch: 17/100... Training loss: 0.0641\n",
      "Epoch: 17/100... Training loss: 0.0641\n",
      "Epoch: 17/100... Training loss: 0.0635\n",
      "Epoch: 17/100... Training loss: 0.0627\n",
      "Epoch: 17/100... Training loss: 0.0631\n",
      "Epoch: 17/100... Training loss: 0.0630\n",
      "Epoch: 17/100... Training loss: 0.0620\n",
      "Epoch: 17/100... Training loss: 0.0639\n",
      "Epoch: 17/100... Training loss: 0.0636\n",
      "Epoch: 17/100... Training loss: 0.0626\n",
      "Epoch: 17/100... Training loss: 0.0629\n",
      "Epoch: 17/100... Training loss: 0.0620\n",
      "Epoch: 17/100... Training loss: 0.0634\n",
      "Epoch: 17/100... Training loss: 0.0624\n",
      "Epoch: 17/100... Training loss: 0.0625\n",
      "Epoch: 17/100... Training loss: 0.0632\n",
      "Epoch: 17/100... Training loss: 0.0631\n",
      "Epoch: 17/100... Training loss: 0.0621\n",
      "Epoch: 17/100... Training loss: 0.0632\n",
      "Epoch: 17/100... Training loss: 0.0631\n",
      "Epoch: 17/100... Training loss: 0.0630\n",
      "Epoch: 18/100... Training loss: 0.0633\n",
      "Epoch: 18/100... Training loss: 0.0634\n",
      "Epoch: 18/100... Training loss: 0.0614\n",
      "Epoch: 18/100... Training loss: 0.0625\n",
      "Epoch: 18/100... Training loss: 0.0620\n",
      "Epoch: 18/100... Training loss: 0.0621\n",
      "Epoch: 18/100... Training loss: 0.0620\n",
      "Epoch: 18/100... Training loss: 0.0631\n",
      "Epoch: 18/100... Training loss: 0.0625\n",
      "Epoch: 18/100... Training loss: 0.0617\n",
      "Epoch: 18/100... Training loss: 0.0625\n",
      "Epoch: 18/100... Training loss: 0.0616\n",
      "Epoch: 18/100... Training loss: 0.0623\n",
      "Epoch: 18/100... Training loss: 0.0626\n",
      "Epoch: 18/100... Training loss: 0.0620\n",
      "Epoch: 18/100... Training loss: 0.0619\n",
      "Epoch: 18/100... Training loss: 0.0607\n",
      "Epoch: 18/100... Training loss: 0.0619\n",
      "Epoch: 18/100... Training loss: 0.0626\n",
      "Epoch: 18/100... Training loss: 0.0631\n",
      "Epoch: 18/100... Training loss: 0.0616\n",
      "Epoch: 19/100... Training loss: 0.0616\n",
      "Epoch: 19/100... Training loss: 0.0615\n",
      "Epoch: 19/100... Training loss: 0.0608\n",
      "Epoch: 19/100... Training loss: 0.0614\n",
      "Epoch: 19/100... Training loss: 0.0621\n",
      "Epoch: 19/100... Training loss: 0.0605\n",
      "Epoch: 19/100... Training loss: 0.0618\n",
      "Epoch: 19/100... Training loss: 0.0608\n",
      "Epoch: 19/100... Training loss: 0.0609\n",
      "Epoch: 19/100... Training loss: 0.0606\n",
      "Epoch: 19/100... Training loss: 0.0614\n",
      "Epoch: 19/100... Training loss: 0.0611\n",
      "Epoch: 19/100... Training loss: 0.0609\n",
      "Epoch: 19/100... Training loss: 0.0618\n",
      "Epoch: 19/100... Training loss: 0.0604\n",
      "Epoch: 19/100... Training loss: 0.0616\n",
      "Epoch: 19/100... Training loss: 0.0609\n",
      "Epoch: 19/100... Training loss: 0.0603\n",
      "Epoch: 19/100... Training loss: 0.0608\n",
      "Epoch: 19/100... Training loss: 0.0614\n",
      "Epoch: 19/100... Training loss: 0.0601\n",
      "Epoch: 20/100... Training loss: 0.0612\n",
      "Epoch: 20/100... Training loss: 0.0598\n",
      "Epoch: 20/100... Training loss: 0.0606\n",
      "Epoch: 20/100... Training loss: 0.0605\n",
      "Epoch: 20/100... Training loss: 0.0604\n",
      "Epoch: 20/100... Training loss: 0.0603\n",
      "Epoch: 20/100... Training loss: 0.0604\n",
      "Epoch: 20/100... Training loss: 0.0600\n",
      "Epoch: 20/100... Training loss: 0.0604\n",
      "Epoch: 20/100... Training loss: 0.0602\n",
      "Epoch: 20/100... Training loss: 0.0604\n",
      "Epoch: 20/100... Training loss: 0.0604\n",
      "Epoch: 20/100... Training loss: 0.0607\n",
      "Epoch: 20/100... Training loss: 0.0596\n",
      "Epoch: 20/100... Training loss: 0.0604\n",
      "Epoch: 20/100... Training loss: 0.0600\n",
      "Epoch: 20/100... Training loss: 0.0593\n",
      "Epoch: 20/100... Training loss: 0.0597\n",
      "Epoch: 20/100... Training loss: 0.0601\n",
      "Epoch: 20/100... Training loss: 0.0596\n",
      "Epoch: 20/100... Training loss: 0.0602\n",
      "Epoch: 21/100... Training loss: 0.0594\n",
      "Epoch: 21/100... Training loss: 0.0598\n",
      "Epoch: 21/100... Training loss: 0.0604\n",
      "Epoch: 21/100... Training loss: 0.0594\n",
      "Epoch: 21/100... Training loss: 0.0593\n",
      "Epoch: 21/100... Training loss: 0.0608\n",
      "Epoch: 21/100... Training loss: 0.0596\n",
      "Epoch: 21/100... Training loss: 0.0596\n",
      "Epoch: 21/100... Training loss: 0.0591\n",
      "Epoch: 21/100... Training loss: 0.0590\n",
      "Epoch: 21/100... Training loss: 0.0605\n",
      "Epoch: 21/100... Training loss: 0.0603\n",
      "Epoch: 21/100... Training loss: 0.0592\n",
      "Epoch: 21/100... Training loss: 0.0597\n",
      "Epoch: 21/100... Training loss: 0.0605\n",
      "Epoch: 21/100... Training loss: 0.0588\n",
      "Epoch: 21/100... Training loss: 0.0586\n",
      "Epoch: 21/100... Training loss: 0.0596\n",
      "Epoch: 21/100... Training loss: 0.0601\n",
      "Epoch: 21/100... Training loss: 0.0584\n",
      "Epoch: 21/100... Training loss: 0.0595\n",
      "Epoch: 22/100... Training loss: 0.0583\n",
      "Epoch: 22/100... Training loss: 0.0592\n",
      "Epoch: 22/100... Training loss: 0.0593\n",
      "Epoch: 22/100... Training loss: 0.0595\n",
      "Epoch: 22/100... Training loss: 0.0590\n",
      "Epoch: 22/100... Training loss: 0.0588\n",
      "Epoch: 22/100... Training loss: 0.0592\n",
      "Epoch: 22/100... Training loss: 0.0586\n",
      "Epoch: 22/100... Training loss: 0.0586\n",
      "Epoch: 22/100... Training loss: 0.0577\n",
      "Epoch: 22/100... Training loss: 0.0581\n",
      "Epoch: 22/100... Training loss: 0.0590\n",
      "Epoch: 22/100... Training loss: 0.0581\n",
      "Epoch: 22/100... Training loss: 0.0595\n",
      "Epoch: 22/100... Training loss: 0.0591\n",
      "Epoch: 22/100... Training loss: 0.0598\n",
      "Epoch: 22/100... Training loss: 0.0591\n",
      "Epoch: 22/100... Training loss: 0.0587\n",
      "Epoch: 22/100... Training loss: 0.0588\n",
      "Epoch: 22/100... Training loss: 0.0580\n",
      "Epoch: 22/100... Training loss: 0.0588\n",
      "Epoch: 23/100... Training loss: 0.0586\n",
      "Epoch: 23/100... Training loss: 0.0583\n",
      "Epoch: 23/100... Training loss: 0.0587\n",
      "Epoch: 23/100... Training loss: 0.0584\n",
      "Epoch: 23/100... Training loss: 0.0581\n",
      "Epoch: 23/100... Training loss: 0.0593\n",
      "Epoch: 23/100... Training loss: 0.0587\n",
      "Epoch: 23/100... Training loss: 0.0574\n",
      "Epoch: 23/100... Training loss: 0.0579\n",
      "Epoch: 23/100... Training loss: 0.0585\n",
      "Epoch: 23/100... Training loss: 0.0578\n",
      "Epoch: 23/100... Training loss: 0.0582\n",
      "Epoch: 23/100... Training loss: 0.0591\n",
      "Epoch: 23/100... Training loss: 0.0576\n",
      "Epoch: 23/100... Training loss: 0.0583\n",
      "Epoch: 23/100... Training loss: 0.0587\n",
      "Epoch: 23/100... Training loss: 0.0588\n",
      "Epoch: 23/100... Training loss: 0.0573\n",
      "Epoch: 23/100... Training loss: 0.0576\n",
      "Epoch: 23/100... Training loss: 0.0583\n",
      "Epoch: 23/100... Training loss: 0.0572\n",
      "Epoch: 24/100... Training loss: 0.0580\n",
      "Epoch: 24/100... Training loss: 0.0580\n",
      "Epoch: 24/100... Training loss: 0.0570\n",
      "Epoch: 24/100... Training loss: 0.0583\n",
      "Epoch: 24/100... Training loss: 0.0569\n",
      "Epoch: 24/100... Training loss: 0.0572\n",
      "Epoch: 24/100... Training loss: 0.0574\n",
      "Epoch: 24/100... Training loss: 0.0575\n",
      "Epoch: 24/100... Training loss: 0.0571\n",
      "Epoch: 24/100... Training loss: 0.0585\n",
      "Epoch: 24/100... Training loss: 0.0578\n",
      "Epoch: 24/100... Training loss: 0.0576\n",
      "Epoch: 24/100... Training loss: 0.0567\n",
      "Epoch: 24/100... Training loss: 0.0579\n",
      "Epoch: 24/100... Training loss: 0.0570\n",
      "Epoch: 24/100... Training loss: 0.0577\n",
      "Epoch: 24/100... Training loss: 0.0572\n",
      "Epoch: 24/100... Training loss: 0.0577\n",
      "Epoch: 24/100... Training loss: 0.0581\n",
      "Epoch: 24/100... Training loss: 0.0583\n",
      "Epoch: 24/100... Training loss: 0.0571\n",
      "Epoch: 25/100... Training loss: 0.0572\n",
      "Epoch: 25/100... Training loss: 0.0566\n",
      "Epoch: 25/100... Training loss: 0.0564\n",
      "Epoch: 25/100... Training loss: 0.0571\n",
      "Epoch: 25/100... Training loss: 0.0578\n",
      "Epoch: 25/100... Training loss: 0.0565\n",
      "Epoch: 25/100... Training loss: 0.0563\n",
      "Epoch: 25/100... Training loss: 0.0572\n",
      "Epoch: 25/100... Training loss: 0.0568\n",
      "Epoch: 25/100... Training loss: 0.0562\n",
      "Epoch: 25/100... Training loss: 0.0578\n",
      "Epoch: 25/100... Training loss: 0.0573\n",
      "Epoch: 25/100... Training loss: 0.0555\n",
      "Epoch: 25/100... Training loss: 0.0569\n",
      "Epoch: 25/100... Training loss: 0.0581\n",
      "Epoch: 25/100... Training loss: 0.0567\n",
      "Epoch: 25/100... Training loss: 0.0559\n",
      "Epoch: 25/100... Training loss: 0.0574\n",
      "Epoch: 25/100... Training loss: 0.0567\n",
      "Epoch: 25/100... Training loss: 0.0566\n",
      "Epoch: 25/100... Training loss: 0.0564\n",
      "Epoch: 26/100... Training loss: 0.0571\n",
      "Epoch: 26/100... Training loss: 0.0572\n",
      "Epoch: 26/100... Training loss: 0.0561\n",
      "Epoch: 26/100... Training loss: 0.0574\n",
      "Epoch: 26/100... Training loss: 0.0563\n",
      "Epoch: 26/100... Training loss: 0.0568\n",
      "Epoch: 26/100... Training loss: 0.0564\n",
      "Epoch: 26/100... Training loss: 0.0557\n",
      "Epoch: 26/100... Training loss: 0.0568\n",
      "Epoch: 26/100... Training loss: 0.0567\n",
      "Epoch: 26/100... Training loss: 0.0560\n",
      "Epoch: 26/100... Training loss: 0.0559\n",
      "Epoch: 26/100... Training loss: 0.0566\n",
      "Epoch: 26/100... Training loss: 0.0565\n",
      "Epoch: 26/100... Training loss: 0.0567\n",
      "Epoch: 26/100... Training loss: 0.0564\n",
      "Epoch: 26/100... Training loss: 0.0564\n",
      "Epoch: 26/100... Training loss: 0.0566\n",
      "Epoch: 26/100... Training loss: 0.0554\n",
      "Epoch: 26/100... Training loss: 0.0572\n",
      "Epoch: 26/100... Training loss: 0.0558\n",
      "Epoch: 27/100... Training loss: 0.0554\n",
      "Epoch: 27/100... Training loss: 0.0558\n",
      "Epoch: 27/100... Training loss: 0.0558\n",
      "Epoch: 27/100... Training loss: 0.0560\n",
      "Epoch: 27/100... Training loss: 0.0566\n",
      "Epoch: 27/100... Training loss: 0.0552\n",
      "Epoch: 27/100... Training loss: 0.0557\n",
      "Epoch: 27/100... Training loss: 0.0550\n",
      "Epoch: 27/100... Training loss: 0.0560\n",
      "Epoch: 27/100... Training loss: 0.0563\n",
      "Epoch: 27/100... Training loss: 0.0565\n",
      "Epoch: 27/100... Training loss: 0.0561\n",
      "Epoch: 27/100... Training loss: 0.0557\n",
      "Epoch: 27/100... Training loss: 0.0553\n",
      "Epoch: 27/100... Training loss: 0.0561\n",
      "Epoch: 27/100... Training loss: 0.0555\n",
      "Epoch: 27/100... Training loss: 0.0565\n",
      "Epoch: 27/100... Training loss: 0.0553\n",
      "Epoch: 27/100... Training loss: 0.0562\n",
      "Epoch: 27/100... Training loss: 0.0558\n",
      "Epoch: 27/100... Training loss: 0.0558\n",
      "Epoch: 28/100... Training loss: 0.0557\n",
      "Epoch: 28/100... Training loss: 0.0555\n",
      "Epoch: 28/100... Training loss: 0.0553\n",
      "Epoch: 28/100... Training loss: 0.0560\n",
      "Epoch: 28/100... Training loss: 0.0561\n",
      "Epoch: 28/100... Training loss: 0.0540\n",
      "Epoch: 28/100... Training loss: 0.0559\n",
      "Epoch: 28/100... Training loss: 0.0555\n",
      "Epoch: 28/100... Training loss: 0.0552\n",
      "Epoch: 28/100... Training loss: 0.0549\n",
      "Epoch: 28/100... Training loss: 0.0560\n",
      "Epoch: 28/100... Training loss: 0.0544\n",
      "Epoch: 28/100... Training loss: 0.0542\n",
      "Epoch: 28/100... Training loss: 0.0543\n",
      "Epoch: 28/100... Training loss: 0.0544\n",
      "Epoch: 28/100... Training loss: 0.0548\n",
      "Epoch: 28/100... Training loss: 0.0556\n",
      "Epoch: 28/100... Training loss: 0.0544\n",
      "Epoch: 28/100... Training loss: 0.0548\n",
      "Epoch: 28/100... Training loss: 0.0548\n",
      "Epoch: 28/100... Training loss: 0.0545\n",
      "Epoch: 29/100... Training loss: 0.0550\n",
      "Epoch: 29/100... Training loss: 0.0549\n",
      "Epoch: 29/100... Training loss: 0.0542\n",
      "Epoch: 29/100... Training loss: 0.0558\n",
      "Epoch: 29/100... Training loss: 0.0543\n",
      "Epoch: 29/100... Training loss: 0.0551\n",
      "Epoch: 29/100... Training loss: 0.0565\n",
      "Epoch: 29/100... Training loss: 0.0552\n",
      "Epoch: 29/100... Training loss: 0.0554\n",
      "Epoch: 29/100... Training loss: 0.0551\n",
      "Epoch: 29/100... Training loss: 0.0559\n",
      "Epoch: 29/100... Training loss: 0.0548\n",
      "Epoch: 29/100... Training loss: 0.0538\n",
      "Epoch: 29/100... Training loss: 0.0543\n",
      "Epoch: 29/100... Training loss: 0.0549\n",
      "Epoch: 29/100... Training loss: 0.0546\n",
      "Epoch: 29/100... Training loss: 0.0551\n",
      "Epoch: 29/100... Training loss: 0.0547\n",
      "Epoch: 29/100... Training loss: 0.0539\n",
      "Epoch: 29/100... Training loss: 0.0551\n",
      "Epoch: 29/100... Training loss: 0.0548\n",
      "Epoch: 30/100... Training loss: 0.0552\n",
      "Epoch: 30/100... Training loss: 0.0551\n",
      "Epoch: 30/100... Training loss: 0.0551\n",
      "Epoch: 30/100... Training loss: 0.0543\n",
      "Epoch: 30/100... Training loss: 0.0540\n",
      "Epoch: 30/100... Training loss: 0.0551\n",
      "Epoch: 30/100... Training loss: 0.0547\n",
      "Epoch: 30/100... Training loss: 0.0548\n",
      "Epoch: 30/100... Training loss: 0.0548\n",
      "Epoch: 30/100... Training loss: 0.0545\n",
      "Epoch: 30/100... Training loss: 0.0550\n",
      "Epoch: 30/100... Training loss: 0.0544\n",
      "Epoch: 30/100... Training loss: 0.0536\n",
      "Epoch: 30/100... Training loss: 0.0550\n",
      "Epoch: 30/100... Training loss: 0.0542\n",
      "Epoch: 30/100... Training loss: 0.0555\n",
      "Epoch: 30/100... Training loss: 0.0535\n",
      "Epoch: 30/100... Training loss: 0.0552\n",
      "Epoch: 30/100... Training loss: 0.0548\n",
      "Epoch: 30/100... Training loss: 0.0548\n",
      "Epoch: 30/100... Training loss: 0.0541\n",
      "Epoch: 31/100... Training loss: 0.0540\n",
      "Epoch: 31/100... Training loss: 0.0560\n",
      "Epoch: 31/100... Training loss: 0.0546\n",
      "Epoch: 31/100... Training loss: 0.0545\n",
      "Epoch: 31/100... Training loss: 0.0546\n",
      "Epoch: 31/100... Training loss: 0.0543\n",
      "Epoch: 31/100... Training loss: 0.0543\n",
      "Epoch: 31/100... Training loss: 0.0546\n",
      "Epoch: 31/100... Training loss: 0.0540\n",
      "Epoch: 31/100... Training loss: 0.0546\n",
      "Epoch: 31/100... Training loss: 0.0534\n",
      "Epoch: 31/100... Training loss: 0.0541\n",
      "Epoch: 31/100... Training loss: 0.0537\n",
      "Epoch: 31/100... Training loss: 0.0531\n",
      "Epoch: 31/100... Training loss: 0.0535\n",
      "Epoch: 31/100... Training loss: 0.0540\n",
      "Epoch: 31/100... Training loss: 0.0538\n",
      "Epoch: 31/100... Training loss: 0.0536\n",
      "Epoch: 31/100... Training loss: 0.0540\n",
      "Epoch: 31/100... Training loss: 0.0530\n",
      "Epoch: 31/100... Training loss: 0.0544\n",
      "Epoch: 32/100... Training loss: 0.0549\n",
      "Epoch: 32/100... Training loss: 0.0540\n",
      "Epoch: 32/100... Training loss: 0.0532\n",
      "Epoch: 32/100... Training loss: 0.0544\n",
      "Epoch: 32/100... Training loss: 0.0534\n",
      "Epoch: 32/100... Training loss: 0.0539\n",
      "Epoch: 32/100... Training loss: 0.0545\n",
      "Epoch: 32/100... Training loss: 0.0538\n",
      "Epoch: 32/100... Training loss: 0.0530\n",
      "Epoch: 32/100... Training loss: 0.0536\n",
      "Epoch: 32/100... Training loss: 0.0538\n",
      "Epoch: 32/100... Training loss: 0.0532\n",
      "Epoch: 32/100... Training loss: 0.0537\n",
      "Epoch: 32/100... Training loss: 0.0535\n",
      "Epoch: 32/100... Training loss: 0.0529\n",
      "Epoch: 32/100... Training loss: 0.0535\n",
      "Epoch: 32/100... Training loss: 0.0545\n",
      "Epoch: 32/100... Training loss: 0.0536\n",
      "Epoch: 32/100... Training loss: 0.0532\n",
      "Epoch: 32/100... Training loss: 0.0535\n",
      "Epoch: 32/100... Training loss: 0.0543\n",
      "Epoch: 33/100... Training loss: 0.0538\n",
      "Epoch: 33/100... Training loss: 0.0534\n",
      "Epoch: 33/100... Training loss: 0.0542\n",
      "Epoch: 33/100... Training loss: 0.0535\n",
      "Epoch: 33/100... Training loss: 0.0526\n",
      "Epoch: 33/100... Training loss: 0.0540\n",
      "Epoch: 33/100... Training loss: 0.0537\n",
      "Epoch: 33/100... Training loss: 0.0534\n",
      "Epoch: 33/100... Training loss: 0.0531\n",
      "Epoch: 33/100... Training loss: 0.0539\n",
      "Epoch: 33/100... Training loss: 0.0543\n",
      "Epoch: 33/100... Training loss: 0.0529\n",
      "Epoch: 33/100... Training loss: 0.0532\n",
      "Epoch: 33/100... Training loss: 0.0546\n",
      "Epoch: 33/100... Training loss: 0.0525\n",
      "Epoch: 33/100... Training loss: 0.0531\n",
      "Epoch: 33/100... Training loss: 0.0531\n",
      "Epoch: 33/100... Training loss: 0.0536\n",
      "Epoch: 33/100... Training loss: 0.0530\n",
      "Epoch: 33/100... Training loss: 0.0529\n",
      "Epoch: 33/100... Training loss: 0.0532\n",
      "Epoch: 34/100... Training loss: 0.0530\n",
      "Epoch: 34/100... Training loss: 0.0540\n",
      "Epoch: 34/100... Training loss: 0.0533\n",
      "Epoch: 34/100... Training loss: 0.0534\n",
      "Epoch: 34/100... Training loss: 0.0529\n",
      "Epoch: 34/100... Training loss: 0.0534\n",
      "Epoch: 34/100... Training loss: 0.0550\n",
      "Epoch: 34/100... Training loss: 0.0529\n",
      "Epoch: 34/100... Training loss: 0.0531\n",
      "Epoch: 34/100... Training loss: 0.0542\n",
      "Epoch: 34/100... Training loss: 0.0533\n",
      "Epoch: 34/100... Training loss: 0.0539\n",
      "Epoch: 34/100... Training loss: 0.0531\n",
      "Epoch: 34/100... Training loss: 0.0534\n",
      "Epoch: 34/100... Training loss: 0.0527\n",
      "Epoch: 34/100... Training loss: 0.0536\n",
      "Epoch: 34/100... Training loss: 0.0535\n",
      "Epoch: 34/100... Training loss: 0.0530\n",
      "Epoch: 34/100... Training loss: 0.0537\n",
      "Epoch: 34/100... Training loss: 0.0529\n",
      "Epoch: 34/100... Training loss: 0.0527\n",
      "Epoch: 35/100... Training loss: 0.0528\n",
      "Epoch: 35/100... Training loss: 0.0528\n",
      "Epoch: 35/100... Training loss: 0.0529\n",
      "Epoch: 35/100... Training loss: 0.0532\n",
      "Epoch: 35/100... Training loss: 0.0526\n",
      "Epoch: 35/100... Training loss: 0.0524\n",
      "Epoch: 35/100... Training loss: 0.0538\n",
      "Epoch: 35/100... Training loss: 0.0530\n",
      "Epoch: 35/100... Training loss: 0.0539\n",
      "Epoch: 35/100... Training loss: 0.0534\n",
      "Epoch: 35/100... Training loss: 0.0527\n",
      "Epoch: 35/100... Training loss: 0.0523\n",
      "Epoch: 35/100... Training loss: 0.0527\n",
      "Epoch: 35/100... Training loss: 0.0521\n",
      "Epoch: 35/100... Training loss: 0.0532\n",
      "Epoch: 35/100... Training loss: 0.0527\n",
      "Epoch: 35/100... Training loss: 0.0526\n",
      "Epoch: 35/100... Training loss: 0.0519\n",
      "Epoch: 35/100... Training loss: 0.0521\n",
      "Epoch: 35/100... Training loss: 0.0531\n",
      "Epoch: 35/100... Training loss: 0.0520\n",
      "Epoch: 36/100... Training loss: 0.0527\n",
      "Epoch: 36/100... Training loss: 0.0525\n",
      "Epoch: 36/100... Training loss: 0.0529\n",
      "Epoch: 36/100... Training loss: 0.0528\n",
      "Epoch: 36/100... Training loss: 0.0523\n",
      "Epoch: 36/100... Training loss: 0.0528\n",
      "Epoch: 36/100... Training loss: 0.0528\n",
      "Epoch: 36/100... Training loss: 0.0528\n",
      "Epoch: 36/100... Training loss: 0.0530\n",
      "Epoch: 36/100... Training loss: 0.0527\n",
      "Epoch: 36/100... Training loss: 0.0521\n",
      "Epoch: 36/100... Training loss: 0.0525\n",
      "Epoch: 36/100... Training loss: 0.0529\n",
      "Epoch: 36/100... Training loss: 0.0530\n",
      "Epoch: 36/100... Training loss: 0.0528\n",
      "Epoch: 36/100... Training loss: 0.0529\n",
      "Epoch: 36/100... Training loss: 0.0518\n",
      "Epoch: 36/100... Training loss: 0.0520\n",
      "Epoch: 36/100... Training loss: 0.0519\n",
      "Epoch: 36/100... Training loss: 0.0527\n",
      "Epoch: 36/100... Training loss: 0.0529\n",
      "Epoch: 37/100... Training loss: 0.0531\n",
      "Epoch: 37/100... Training loss: 0.0526\n",
      "Epoch: 37/100... Training loss: 0.0532\n",
      "Epoch: 37/100... Training loss: 0.0520\n",
      "Epoch: 37/100... Training loss: 0.0520\n",
      "Epoch: 37/100... Training loss: 0.0521\n",
      "Epoch: 37/100... Training loss: 0.0518\n",
      "Epoch: 37/100... Training loss: 0.0524\n",
      "Epoch: 37/100... Training loss: 0.0520\n",
      "Epoch: 37/100... Training loss: 0.0522\n",
      "Epoch: 37/100... Training loss: 0.0527\n",
      "Epoch: 37/100... Training loss: 0.0525\n",
      "Epoch: 37/100... Training loss: 0.0522\n",
      "Epoch: 37/100... Training loss: 0.0526\n",
      "Epoch: 37/100... Training loss: 0.0529\n",
      "Epoch: 37/100... Training loss: 0.0522\n",
      "Epoch: 37/100... Training loss: 0.0520\n",
      "Epoch: 37/100... Training loss: 0.0517\n",
      "Epoch: 37/100... Training loss: 0.0526\n",
      "Epoch: 37/100... Training loss: 0.0510\n",
      "Epoch: 37/100... Training loss: 0.0522\n",
      "Epoch: 38/100... Training loss: 0.0529\n",
      "Epoch: 38/100... Training loss: 0.0519\n",
      "Epoch: 38/100... Training loss: 0.0523\n",
      "Epoch: 38/100... Training loss: 0.0529\n",
      "Epoch: 38/100... Training loss: 0.0520\n",
      "Epoch: 38/100... Training loss: 0.0517\n",
      "Epoch: 38/100... Training loss: 0.0518\n",
      "Epoch: 38/100... Training loss: 0.0526\n",
      "Epoch: 38/100... Training loss: 0.0517\n",
      "Epoch: 38/100... Training loss: 0.0525\n",
      "Epoch: 38/100... Training loss: 0.0526\n",
      "Epoch: 38/100... Training loss: 0.0517\n",
      "Epoch: 38/100... Training loss: 0.0517\n",
      "Epoch: 38/100... Training loss: 0.0524\n",
      "Epoch: 38/100... Training loss: 0.0515\n",
      "Epoch: 38/100... Training loss: 0.0523\n",
      "Epoch: 38/100... Training loss: 0.0520\n",
      "Epoch: 38/100... Training loss: 0.0516\n",
      "Epoch: 38/100... Training loss: 0.0518\n",
      "Epoch: 38/100... Training loss: 0.0518\n",
      "Epoch: 38/100... Training loss: 0.0521\n",
      "Epoch: 39/100... Training loss: 0.0511\n",
      "Epoch: 39/100... Training loss: 0.0520\n",
      "Epoch: 39/100... Training loss: 0.0519\n",
      "Epoch: 39/100... Training loss: 0.0510\n",
      "Epoch: 39/100... Training loss: 0.0514\n",
      "Epoch: 39/100... Training loss: 0.0516\n",
      "Epoch: 39/100... Training loss: 0.0520\n",
      "Epoch: 39/100... Training loss: 0.0518\n",
      "Epoch: 39/100... Training loss: 0.0524\n",
      "Epoch: 39/100... Training loss: 0.0517\n",
      "Epoch: 39/100... Training loss: 0.0515\n",
      "Epoch: 39/100... Training loss: 0.0517\n",
      "Epoch: 39/100... Training loss: 0.0522\n",
      "Epoch: 39/100... Training loss: 0.0510\n",
      "Epoch: 39/100... Training loss: 0.0525\n",
      "Epoch: 39/100... Training loss: 0.0520\n",
      "Epoch: 39/100... Training loss: 0.0513\n",
      "Epoch: 39/100... Training loss: 0.0514\n",
      "Epoch: 39/100... Training loss: 0.0509\n",
      "Epoch: 39/100... Training loss: 0.0514\n",
      "Epoch: 39/100... Training loss: 0.0511\n",
      "Epoch: 40/100... Training loss: 0.0514\n",
      "Epoch: 40/100... Training loss: 0.0507\n",
      "Epoch: 40/100... Training loss: 0.0523\n",
      "Epoch: 40/100... Training loss: 0.0523\n",
      "Epoch: 40/100... Training loss: 0.0527\n",
      "Epoch: 40/100... Training loss: 0.0524\n",
      "Epoch: 40/100... Training loss: 0.0517\n",
      "Epoch: 40/100... Training loss: 0.0510\n",
      "Epoch: 40/100... Training loss: 0.0527\n",
      "Epoch: 40/100... Training loss: 0.0516\n",
      "Epoch: 40/100... Training loss: 0.0518\n",
      "Epoch: 40/100... Training loss: 0.0513\n",
      "Epoch: 40/100... Training loss: 0.0518\n",
      "Epoch: 40/100... Training loss: 0.0513\n",
      "Epoch: 40/100... Training loss: 0.0521\n",
      "Epoch: 40/100... Training loss: 0.0516\n",
      "Epoch: 40/100... Training loss: 0.0513\n",
      "Epoch: 40/100... Training loss: 0.0517\n",
      "Epoch: 40/100... Training loss: 0.0510\n",
      "Epoch: 40/100... Training loss: 0.0509\n",
      "Epoch: 40/100... Training loss: 0.0511\n",
      "Epoch: 41/100... Training loss: 0.0515\n",
      "Epoch: 41/100... Training loss: 0.0517\n",
      "Epoch: 41/100... Training loss: 0.0513\n",
      "Epoch: 41/100... Training loss: 0.0517\n",
      "Epoch: 41/100... Training loss: 0.0515\n",
      "Epoch: 41/100... Training loss: 0.0516\n",
      "Epoch: 41/100... Training loss: 0.0518\n",
      "Epoch: 41/100... Training loss: 0.0514\n",
      "Epoch: 41/100... Training loss: 0.0513\n",
      "Epoch: 41/100... Training loss: 0.0515\n",
      "Epoch: 41/100... Training loss: 0.0504\n",
      "Epoch: 41/100... Training loss: 0.0507\n",
      "Epoch: 41/100... Training loss: 0.0516\n",
      "Epoch: 41/100... Training loss: 0.0518\n",
      "Epoch: 41/100... Training loss: 0.0509\n",
      "Epoch: 41/100... Training loss: 0.0511\n",
      "Epoch: 41/100... Training loss: 0.0509\n",
      "Epoch: 41/100... Training loss: 0.0513\n",
      "Epoch: 41/100... Training loss: 0.0512\n",
      "Epoch: 41/100... Training loss: 0.0508\n",
      "Epoch: 41/100... Training loss: 0.0506\n",
      "Epoch: 42/100... Training loss: 0.0519\n",
      "Epoch: 42/100... Training loss: 0.0510\n",
      "Epoch: 42/100... Training loss: 0.0517\n",
      "Epoch: 42/100... Training loss: 0.0511\n",
      "Epoch: 42/100... Training loss: 0.0518\n",
      "Epoch: 42/100... Training loss: 0.0504\n",
      "Epoch: 42/100... Training loss: 0.0513\n",
      "Epoch: 42/100... Training loss: 0.0511\n",
      "Epoch: 42/100... Training loss: 0.0512\n",
      "Epoch: 42/100... Training loss: 0.0508\n",
      "Epoch: 42/100... Training loss: 0.0515\n",
      "Epoch: 42/100... Training loss: 0.0508\n",
      "Epoch: 42/100... Training loss: 0.0514\n",
      "Epoch: 42/100... Training loss: 0.0510\n",
      "Epoch: 42/100... Training loss: 0.0519\n",
      "Epoch: 42/100... Training loss: 0.0508\n",
      "Epoch: 42/100... Training loss: 0.0510\n",
      "Epoch: 42/100... Training loss: 0.0514\n",
      "Epoch: 42/100... Training loss: 0.0517\n",
      "Epoch: 42/100... Training loss: 0.0511\n",
      "Epoch: 42/100... Training loss: 0.0504\n",
      "Epoch: 43/100... Training loss: 0.0503\n",
      "Epoch: 43/100... Training loss: 0.0503\n",
      "Epoch: 43/100... Training loss: 0.0508\n",
      "Epoch: 43/100... Training loss: 0.0508\n",
      "Epoch: 43/100... Training loss: 0.0513\n",
      "Epoch: 43/100... Training loss: 0.0506\n",
      "Epoch: 43/100... Training loss: 0.0506\n",
      "Epoch: 43/100... Training loss: 0.0507\n",
      "Epoch: 43/100... Training loss: 0.0510\n",
      "Epoch: 43/100... Training loss: 0.0508\n",
      "Epoch: 43/100... Training loss: 0.0502\n",
      "Epoch: 43/100... Training loss: 0.0503\n",
      "Epoch: 43/100... Training loss: 0.0504\n",
      "Epoch: 43/100... Training loss: 0.0501\n",
      "Epoch: 43/100... Training loss: 0.0504\n",
      "Epoch: 43/100... Training loss: 0.0504\n",
      "Epoch: 43/100... Training loss: 0.0503\n",
      "Epoch: 43/100... Training loss: 0.0511\n",
      "Epoch: 43/100... Training loss: 0.0510\n",
      "Epoch: 43/100... Training loss: 0.0507\n",
      "Epoch: 43/100... Training loss: 0.0503\n",
      "Epoch: 44/100... Training loss: 0.0507\n",
      "Epoch: 44/100... Training loss: 0.0516\n",
      "Epoch: 44/100... Training loss: 0.0509\n",
      "Epoch: 44/100... Training loss: 0.0501\n",
      "Epoch: 44/100... Training loss: 0.0497\n",
      "Epoch: 44/100... Training loss: 0.0500\n",
      "Epoch: 44/100... Training loss: 0.0517\n",
      "Epoch: 44/100... Training loss: 0.0509\n",
      "Epoch: 44/100... Training loss: 0.0510\n",
      "Epoch: 44/100... Training loss: 0.0508\n",
      "Epoch: 44/100... Training loss: 0.0505\n",
      "Epoch: 44/100... Training loss: 0.0514\n",
      "Epoch: 44/100... Training loss: 0.0506\n",
      "Epoch: 44/100... Training loss: 0.0514\n",
      "Epoch: 44/100... Training loss: 0.0508\n",
      "Epoch: 44/100... Training loss: 0.0504\n",
      "Epoch: 44/100... Training loss: 0.0505\n",
      "Epoch: 44/100... Training loss: 0.0510\n",
      "Epoch: 44/100... Training loss: 0.0507\n",
      "Epoch: 44/100... Training loss: 0.0506\n",
      "Epoch: 44/100... Training loss: 0.0508\n",
      "Epoch: 45/100... Training loss: 0.0508\n",
      "Epoch: 45/100... Training loss: 0.0503\n",
      "Epoch: 45/100... Training loss: 0.0500\n",
      "Epoch: 45/100... Training loss: 0.0509\n",
      "Epoch: 45/100... Training loss: 0.0515\n",
      "Epoch: 45/100... Training loss: 0.0504\n",
      "Epoch: 45/100... Training loss: 0.0502\n",
      "Epoch: 45/100... Training loss: 0.0503\n",
      "Epoch: 45/100... Training loss: 0.0501\n",
      "Epoch: 45/100... Training loss: 0.0504\n",
      "Epoch: 45/100... Training loss: 0.0497\n",
      "Epoch: 45/100... Training loss: 0.0509\n",
      "Epoch: 45/100... Training loss: 0.0504\n",
      "Epoch: 45/100... Training loss: 0.0496\n",
      "Epoch: 45/100... Training loss: 0.0499\n",
      "Epoch: 45/100... Training loss: 0.0501\n",
      "Epoch: 45/100... Training loss: 0.0501\n",
      "Epoch: 45/100... Training loss: 0.0494\n",
      "Epoch: 45/100... Training loss: 0.0504\n",
      "Epoch: 45/100... Training loss: 0.0508\n",
      "Epoch: 45/100... Training loss: 0.0506\n",
      "Epoch: 46/100... Training loss: 0.0503\n",
      "Epoch: 46/100... Training loss: 0.0497\n",
      "Epoch: 46/100... Training loss: 0.0506\n",
      "Epoch: 46/100... Training loss: 0.0512\n",
      "Epoch: 46/100... Training loss: 0.0505\n",
      "Epoch: 46/100... Training loss: 0.0498\n",
      "Epoch: 46/100... Training loss: 0.0509\n",
      "Epoch: 46/100... Training loss: 0.0506\n",
      "Epoch: 46/100... Training loss: 0.0500\n",
      "Epoch: 46/100... Training loss: 0.0500\n",
      "Epoch: 46/100... Training loss: 0.0488\n",
      "Epoch: 46/100... Training loss: 0.0500\n",
      "Epoch: 46/100... Training loss: 0.0502\n",
      "Epoch: 46/100... Training loss: 0.0493\n",
      "Epoch: 46/100... Training loss: 0.0494\n",
      "Epoch: 46/100... Training loss: 0.0502\n",
      "Epoch: 46/100... Training loss: 0.0499\n",
      "Epoch: 46/100... Training loss: 0.0505\n",
      "Epoch: 46/100... Training loss: 0.0503\n",
      "Epoch: 46/100... Training loss: 0.0498\n",
      "Epoch: 46/100... Training loss: 0.0502\n",
      "Epoch: 47/100... Training loss: 0.0502\n",
      "Epoch: 47/100... Training loss: 0.0494\n",
      "Epoch: 47/100... Training loss: 0.0495\n",
      "Epoch: 47/100... Training loss: 0.0498\n",
      "Epoch: 47/100... Training loss: 0.0499\n",
      "Epoch: 47/100... Training loss: 0.0501\n",
      "Epoch: 47/100... Training loss: 0.0494\n",
      "Epoch: 47/100... Training loss: 0.0503\n",
      "Epoch: 47/100... Training loss: 0.0490\n",
      "Epoch: 47/100... Training loss: 0.0501\n",
      "Epoch: 47/100... Training loss: 0.0505\n",
      "Epoch: 47/100... Training loss: 0.0504\n",
      "Epoch: 47/100... Training loss: 0.0499\n",
      "Epoch: 47/100... Training loss: 0.0501\n",
      "Epoch: 47/100... Training loss: 0.0504\n",
      "Epoch: 47/100... Training loss: 0.0505\n",
      "Epoch: 47/100... Training loss: 0.0511\n",
      "Epoch: 47/100... Training loss: 0.0499\n",
      "Epoch: 47/100... Training loss: 0.0501\n",
      "Epoch: 47/100... Training loss: 0.0492\n",
      "Epoch: 47/100... Training loss: 0.0493\n",
      "Epoch: 48/100... Training loss: 0.0500\n",
      "Epoch: 48/100... Training loss: 0.0504\n",
      "Epoch: 48/100... Training loss: 0.0497\n",
      "Epoch: 48/100... Training loss: 0.0493\n",
      "Epoch: 48/100... Training loss: 0.0493\n",
      "Epoch: 48/100... Training loss: 0.0496\n",
      "Epoch: 48/100... Training loss: 0.0500\n",
      "Epoch: 48/100... Training loss: 0.0497\n",
      "Epoch: 48/100... Training loss: 0.0496\n",
      "Epoch: 48/100... Training loss: 0.0497\n",
      "Epoch: 48/100... Training loss: 0.0495\n",
      "Epoch: 48/100... Training loss: 0.0507\n",
      "Epoch: 48/100... Training loss: 0.0498\n",
      "Epoch: 48/100... Training loss: 0.0493\n",
      "Epoch: 48/100... Training loss: 0.0488\n",
      "Epoch: 48/100... Training loss: 0.0501\n",
      "Epoch: 48/100... Training loss: 0.0496\n",
      "Epoch: 48/100... Training loss: 0.0495\n",
      "Epoch: 48/100... Training loss: 0.0504\n",
      "Epoch: 48/100... Training loss: 0.0501\n",
      "Epoch: 48/100... Training loss: 0.0495\n",
      "Epoch: 49/100... Training loss: 0.0498\n",
      "Epoch: 49/100... Training loss: 0.0492\n",
      "Epoch: 49/100... Training loss: 0.0507\n",
      "Epoch: 49/100... Training loss: 0.0495\n",
      "Epoch: 49/100... Training loss: 0.0500\n",
      "Epoch: 49/100... Training loss: 0.0498\n",
      "Epoch: 49/100... Training loss: 0.0496\n",
      "Epoch: 49/100... Training loss: 0.0499\n",
      "Epoch: 49/100... Training loss: 0.0499\n",
      "Epoch: 49/100... Training loss: 0.0497\n",
      "Epoch: 49/100... Training loss: 0.0489\n",
      "Epoch: 49/100... Training loss: 0.0492\n",
      "Epoch: 49/100... Training loss: 0.0499\n",
      "Epoch: 49/100... Training loss: 0.0491\n",
      "Epoch: 49/100... Training loss: 0.0499\n",
      "Epoch: 49/100... Training loss: 0.0491\n",
      "Epoch: 49/100... Training loss: 0.0497\n",
      "Epoch: 49/100... Training loss: 0.0507\n",
      "Epoch: 49/100... Training loss: 0.0506\n",
      "Epoch: 49/100... Training loss: 0.0485\n",
      "Epoch: 49/100... Training loss: 0.0501\n",
      "Epoch: 50/100... Training loss: 0.0489\n",
      "Epoch: 50/100... Training loss: 0.0494\n",
      "Epoch: 50/100... Training loss: 0.0499\n",
      "Epoch: 50/100... Training loss: 0.0492\n",
      "Epoch: 50/100... Training loss: 0.0485\n",
      "Epoch: 50/100... Training loss: 0.0494\n",
      "Epoch: 50/100... Training loss: 0.0500\n",
      "Epoch: 50/100... Training loss: 0.0499\n",
      "Epoch: 50/100... Training loss: 0.0499\n",
      "Epoch: 50/100... Training loss: 0.0505\n",
      "Epoch: 50/100... Training loss: 0.0503\n",
      "Epoch: 50/100... Training loss: 0.0496\n",
      "Epoch: 50/100... Training loss: 0.0497\n",
      "Epoch: 50/100... Training loss: 0.0489\n",
      "Epoch: 50/100... Training loss: 0.0494\n",
      "Epoch: 50/100... Training loss: 0.0492\n",
      "Epoch: 50/100... Training loss: 0.0490\n",
      "Epoch: 50/100... Training loss: 0.0482\n",
      "Epoch: 50/100... Training loss: 0.0495\n",
      "Epoch: 50/100... Training loss: 0.0492\n",
      "Epoch: 50/100... Training loss: 0.0489\n",
      "Epoch: 51/100... Training loss: 0.0490\n",
      "Epoch: 51/100... Training loss: 0.0488\n",
      "Epoch: 51/100... Training loss: 0.0494\n",
      "Epoch: 51/100... Training loss: 0.0495\n",
      "Epoch: 51/100... Training loss: 0.0499\n",
      "Epoch: 51/100... Training loss: 0.0490\n",
      "Epoch: 51/100... Training loss: 0.0495\n",
      "Epoch: 51/100... Training loss: 0.0491\n",
      "Epoch: 51/100... Training loss: 0.0493\n",
      "Epoch: 51/100... Training loss: 0.0492\n",
      "Epoch: 51/100... Training loss: 0.0497\n",
      "Epoch: 51/100... Training loss: 0.0491\n",
      "Epoch: 51/100... Training loss: 0.0488\n",
      "Epoch: 51/100... Training loss: 0.0495\n",
      "Epoch: 51/100... Training loss: 0.0492\n",
      "Epoch: 51/100... Training loss: 0.0498\n",
      "Epoch: 51/100... Training loss: 0.0495\n",
      "Epoch: 51/100... Training loss: 0.0488\n",
      "Epoch: 51/100... Training loss: 0.0491\n",
      "Epoch: 51/100... Training loss: 0.0490\n",
      "Epoch: 51/100... Training loss: 0.0490\n",
      "Epoch: 52/100... Training loss: 0.0499\n",
      "Epoch: 52/100... Training loss: 0.0493\n",
      "Epoch: 52/100... Training loss: 0.0488\n",
      "Epoch: 52/100... Training loss: 0.0489\n",
      "Epoch: 52/100... Training loss: 0.0497\n",
      "Epoch: 52/100... Training loss: 0.0491\n",
      "Epoch: 52/100... Training loss: 0.0494\n",
      "Epoch: 52/100... Training loss: 0.0485\n",
      "Epoch: 52/100... Training loss: 0.0510\n",
      "Epoch: 52/100... Training loss: 0.0497\n",
      "Epoch: 52/100... Training loss: 0.0500\n",
      "Epoch: 52/100... Training loss: 0.0489\n",
      "Epoch: 52/100... Training loss: 0.0486\n",
      "Epoch: 52/100... Training loss: 0.0496\n",
      "Epoch: 52/100... Training loss: 0.0483\n",
      "Epoch: 52/100... Training loss: 0.0491\n",
      "Epoch: 52/100... Training loss: 0.0495\n",
      "Epoch: 52/100... Training loss: 0.0500\n",
      "Epoch: 52/100... Training loss: 0.0497\n",
      "Epoch: 52/100... Training loss: 0.0497\n",
      "Epoch: 52/100... Training loss: 0.0489\n",
      "Epoch: 53/100... Training loss: 0.0495\n",
      "Epoch: 53/100... Training loss: 0.0485\n",
      "Epoch: 53/100... Training loss: 0.0499\n",
      "Epoch: 53/100... Training loss: 0.0487\n",
      "Epoch: 53/100... Training loss: 0.0494\n",
      "Epoch: 53/100... Training loss: 0.0494\n",
      "Epoch: 53/100... Training loss: 0.0492\n",
      "Epoch: 53/100... Training loss: 0.0490\n",
      "Epoch: 53/100... Training loss: 0.0488\n",
      "Epoch: 53/100... Training loss: 0.0484\n",
      "Epoch: 53/100... Training loss: 0.0484\n",
      "Epoch: 53/100... Training loss: 0.0492\n",
      "Epoch: 53/100... Training loss: 0.0489\n",
      "Epoch: 53/100... Training loss: 0.0490\n",
      "Epoch: 53/100... Training loss: 0.0485\n",
      "Epoch: 53/100... Training loss: 0.0487\n",
      "Epoch: 53/100... Training loss: 0.0495\n",
      "Epoch: 53/100... Training loss: 0.0489\n",
      "Epoch: 53/100... Training loss: 0.0490\n",
      "Epoch: 53/100... Training loss: 0.0491\n",
      "Epoch: 53/100... Training loss: 0.0488\n",
      "Epoch: 54/100... Training loss: 0.0490\n",
      "Epoch: 54/100... Training loss: 0.0488\n",
      "Epoch: 54/100... Training loss: 0.0484\n",
      "Epoch: 54/100... Training loss: 0.0492\n",
      "Epoch: 54/100... Training loss: 0.0487\n",
      "Epoch: 54/100... Training loss: 0.0492\n",
      "Epoch: 54/100... Training loss: 0.0490\n",
      "Epoch: 54/100... Training loss: 0.0495\n",
      "Epoch: 54/100... Training loss: 0.0493\n",
      "Epoch: 54/100... Training loss: 0.0487\n",
      "Epoch: 54/100... Training loss: 0.0488\n",
      "Epoch: 54/100... Training loss: 0.0482\n",
      "Epoch: 54/100... Training loss: 0.0490\n",
      "Epoch: 54/100... Training loss: 0.0489\n",
      "Epoch: 54/100... Training loss: 0.0496\n",
      "Epoch: 54/100... Training loss: 0.0492\n",
      "Epoch: 54/100... Training loss: 0.0498\n",
      "Epoch: 54/100... Training loss: 0.0491\n",
      "Epoch: 54/100... Training loss: 0.0481\n",
      "Epoch: 54/100... Training loss: 0.0485\n",
      "Epoch: 54/100... Training loss: 0.0484\n",
      "Epoch: 55/100... Training loss: 0.0488\n",
      "Epoch: 55/100... Training loss: 0.0481\n",
      "Epoch: 55/100... Training loss: 0.0492\n",
      "Epoch: 55/100... Training loss: 0.0483\n",
      "Epoch: 55/100... Training loss: 0.0487\n",
      "Epoch: 55/100... Training loss: 0.0479\n",
      "Epoch: 55/100... Training loss: 0.0495\n",
      "Epoch: 55/100... Training loss: 0.0489\n",
      "Epoch: 55/100... Training loss: 0.0486\n",
      "Epoch: 55/100... Training loss: 0.0485\n",
      "Epoch: 55/100... Training loss: 0.0485\n",
      "Epoch: 55/100... Training loss: 0.0484\n",
      "Epoch: 55/100... Training loss: 0.0480\n",
      "Epoch: 55/100... Training loss: 0.0481\n",
      "Epoch: 55/100... Training loss: 0.0494\n",
      "Epoch: 55/100... Training loss: 0.0487\n",
      "Epoch: 55/100... Training loss: 0.0490\n",
      "Epoch: 55/100... Training loss: 0.0486\n",
      "Epoch: 55/100... Training loss: 0.0489\n",
      "Epoch: 55/100... Training loss: 0.0489\n",
      "Epoch: 55/100... Training loss: 0.0485\n",
      "Epoch: 56/100... Training loss: 0.0490\n",
      "Epoch: 56/100... Training loss: 0.0487\n",
      "Epoch: 56/100... Training loss: 0.0483\n",
      "Epoch: 56/100... Training loss: 0.0480\n",
      "Epoch: 56/100... Training loss: 0.0495\n",
      "Epoch: 56/100... Training loss: 0.0496\n",
      "Epoch: 56/100... Training loss: 0.0489\n",
      "Epoch: 56/100... Training loss: 0.0484\n",
      "Epoch: 56/100... Training loss: 0.0479\n",
      "Epoch: 56/100... Training loss: 0.0484\n",
      "Epoch: 56/100... Training loss: 0.0487\n",
      "Epoch: 56/100... Training loss: 0.0485\n",
      "Epoch: 56/100... Training loss: 0.0485\n",
      "Epoch: 56/100... Training loss: 0.0485\n",
      "Epoch: 56/100... Training loss: 0.0482\n",
      "Epoch: 56/100... Training loss: 0.0486\n",
      "Epoch: 56/100... Training loss: 0.0486\n",
      "Epoch: 56/100... Training loss: 0.0486\n",
      "Epoch: 56/100... Training loss: 0.0489\n",
      "Epoch: 56/100... Training loss: 0.0484\n",
      "Epoch: 56/100... Training loss: 0.0491\n",
      "Epoch: 57/100... Training loss: 0.0491\n",
      "Epoch: 57/100... Training loss: 0.0485\n",
      "Epoch: 57/100... Training loss: 0.0486\n",
      "Epoch: 57/100... Training loss: 0.0482\n",
      "Epoch: 57/100... Training loss: 0.0484\n",
      "Epoch: 57/100... Training loss: 0.0484\n",
      "Epoch: 57/100... Training loss: 0.0484\n",
      "Epoch: 57/100... Training loss: 0.0485\n",
      "Epoch: 57/100... Training loss: 0.0480\n",
      "Epoch: 57/100... Training loss: 0.0485\n",
      "Epoch: 57/100... Training loss: 0.0479\n",
      "Epoch: 57/100... Training loss: 0.0490\n",
      "Epoch: 57/100... Training loss: 0.0483\n",
      "Epoch: 57/100... Training loss: 0.0481\n",
      "Epoch: 57/100... Training loss: 0.0494\n",
      "Epoch: 57/100... Training loss: 0.0484\n",
      "Epoch: 57/100... Training loss: 0.0496\n",
      "Epoch: 57/100... Training loss: 0.0481\n",
      "Epoch: 57/100... Training loss: 0.0482\n",
      "Epoch: 57/100... Training loss: 0.0477\n",
      "Epoch: 57/100... Training loss: 0.0486\n",
      "Epoch: 58/100... Training loss: 0.0479\n",
      "Epoch: 58/100... Training loss: 0.0485\n",
      "Epoch: 58/100... Training loss: 0.0484\n",
      "Epoch: 58/100... Training loss: 0.0487\n",
      "Epoch: 58/100... Training loss: 0.0492\n",
      "Epoch: 58/100... Training loss: 0.0488\n",
      "Epoch: 58/100... Training loss: 0.0478\n",
      "Epoch: 58/100... Training loss: 0.0489\n",
      "Epoch: 58/100... Training loss: 0.0494\n",
      "Epoch: 58/100... Training loss: 0.0482\n",
      "Epoch: 58/100... Training loss: 0.0485\n",
      "Epoch: 58/100... Training loss: 0.0480\n",
      "Epoch: 58/100... Training loss: 0.0489\n",
      "Epoch: 58/100... Training loss: 0.0492\n",
      "Epoch: 58/100... Training loss: 0.0488\n",
      "Epoch: 58/100... Training loss: 0.0481\n",
      "Epoch: 58/100... Training loss: 0.0488\n",
      "Epoch: 58/100... Training loss: 0.0476\n",
      "Epoch: 58/100... Training loss: 0.0475\n",
      "Epoch: 58/100... Training loss: 0.0478\n",
      "Epoch: 58/100... Training loss: 0.0484\n",
      "Epoch: 59/100... Training loss: 0.0484\n",
      "Epoch: 59/100... Training loss: 0.0479\n",
      "Epoch: 59/100... Training loss: 0.0486\n",
      "Epoch: 59/100... Training loss: 0.0471\n",
      "Epoch: 59/100... Training loss: 0.0486\n",
      "Epoch: 59/100... Training loss: 0.0478\n",
      "Epoch: 59/100... Training loss: 0.0478\n",
      "Epoch: 59/100... Training loss: 0.0488\n",
      "Epoch: 59/100... Training loss: 0.0476\n",
      "Epoch: 59/100... Training loss: 0.0488\n",
      "Epoch: 59/100... Training loss: 0.0473\n",
      "Epoch: 59/100... Training loss: 0.0483\n",
      "Epoch: 59/100... Training loss: 0.0482\n",
      "Epoch: 59/100... Training loss: 0.0475\n",
      "Epoch: 59/100... Training loss: 0.0471\n",
      "Epoch: 59/100... Training loss: 0.0480\n",
      "Epoch: 59/100... Training loss: 0.0480\n",
      "Epoch: 59/100... Training loss: 0.0473\n",
      "Epoch: 59/100... Training loss: 0.0490\n",
      "Epoch: 59/100... Training loss: 0.0481\n",
      "Epoch: 59/100... Training loss: 0.0485\n",
      "Epoch: 60/100... Training loss: 0.0489\n",
      "Epoch: 60/100... Training loss: 0.0497\n",
      "Epoch: 60/100... Training loss: 0.0493\n",
      "Epoch: 60/100... Training loss: 0.0481\n",
      "Epoch: 60/100... Training loss: 0.0477\n",
      "Epoch: 60/100... Training loss: 0.0487\n",
      "Epoch: 60/100... Training loss: 0.0493\n",
      "Epoch: 60/100... Training loss: 0.0486\n",
      "Epoch: 60/100... Training loss: 0.0485\n",
      "Epoch: 60/100... Training loss: 0.0496\n",
      "Epoch: 60/100... Training loss: 0.0493\n",
      "Epoch: 60/100... Training loss: 0.0481\n",
      "Epoch: 60/100... Training loss: 0.0493\n",
      "Epoch: 60/100... Training loss: 0.0478\n",
      "Epoch: 60/100... Training loss: 0.0482\n",
      "Epoch: 60/100... Training loss: 0.0486\n",
      "Epoch: 60/100... Training loss: 0.0479\n",
      "Epoch: 60/100... Training loss: 0.0473\n",
      "Epoch: 60/100... Training loss: 0.0484\n",
      "Epoch: 60/100... Training loss: 0.0486\n",
      "Epoch: 60/100... Training loss: 0.0480\n",
      "Epoch: 61/100... Training loss: 0.0482\n",
      "Epoch: 61/100... Training loss: 0.0478\n",
      "Epoch: 61/100... Training loss: 0.0479\n",
      "Epoch: 61/100... Training loss: 0.0472\n",
      "Epoch: 61/100... Training loss: 0.0479\n",
      "Epoch: 61/100... Training loss: 0.0483\n",
      "Epoch: 61/100... Training loss: 0.0486\n",
      "Epoch: 61/100... Training loss: 0.0481\n",
      "Epoch: 61/100... Training loss: 0.0477\n",
      "Epoch: 61/100... Training loss: 0.0477\n",
      "Epoch: 61/100... Training loss: 0.0485\n",
      "Epoch: 61/100... Training loss: 0.0480\n",
      "Epoch: 61/100... Training loss: 0.0478\n",
      "Epoch: 61/100... Training loss: 0.0485\n",
      "Epoch: 61/100... Training loss: 0.0480\n",
      "Epoch: 61/100... Training loss: 0.0477\n",
      "Epoch: 61/100... Training loss: 0.0483\n",
      "Epoch: 61/100... Training loss: 0.0463\n",
      "Epoch: 61/100... Training loss: 0.0477\n",
      "Epoch: 61/100... Training loss: 0.0476\n",
      "Epoch: 61/100... Training loss: 0.0478\n",
      "Epoch: 62/100... Training loss: 0.0482\n",
      "Epoch: 62/100... Training loss: 0.0485\n",
      "Epoch: 62/100... Training loss: 0.0478\n",
      "Epoch: 62/100... Training loss: 0.0480\n",
      "Epoch: 62/100... Training loss: 0.0475\n",
      "Epoch: 62/100... Training loss: 0.0476\n",
      "Epoch: 62/100... Training loss: 0.0475\n",
      "Epoch: 62/100... Training loss: 0.0478\n",
      "Epoch: 62/100... Training loss: 0.0480\n",
      "Epoch: 62/100... Training loss: 0.0478\n",
      "Epoch: 62/100... Training loss: 0.0486\n",
      "Epoch: 62/100... Training loss: 0.0476\n",
      "Epoch: 62/100... Training loss: 0.0477\n",
      "Epoch: 62/100... Training loss: 0.0479\n",
      "Epoch: 62/100... Training loss: 0.0479\n",
      "Epoch: 62/100... Training loss: 0.0479\n",
      "Epoch: 62/100... Training loss: 0.0480\n",
      "Epoch: 62/100... Training loss: 0.0479\n",
      "Epoch: 62/100... Training loss: 0.0478\n",
      "Epoch: 62/100... Training loss: 0.0477\n",
      "Epoch: 62/100... Training loss: 0.0479\n",
      "Epoch: 63/100... Training loss: 0.0475\n",
      "Epoch: 63/100... Training loss: 0.0477\n",
      "Epoch: 63/100... Training loss: 0.0477\n",
      "Epoch: 63/100... Training loss: 0.0475\n",
      "Epoch: 63/100... Training loss: 0.0479\n",
      "Epoch: 63/100... Training loss: 0.0474\n",
      "Epoch: 63/100... Training loss: 0.0475\n",
      "Epoch: 63/100... Training loss: 0.0482\n",
      "Epoch: 63/100... Training loss: 0.0483\n",
      "Epoch: 63/100... Training loss: 0.0480\n",
      "Epoch: 63/100... Training loss: 0.0485\n",
      "Epoch: 63/100... Training loss: 0.0482\n",
      "Epoch: 63/100... Training loss: 0.0497\n",
      "Epoch: 63/100... Training loss: 0.0481\n",
      "Epoch: 63/100... Training loss: 0.0505\n",
      "Epoch: 63/100... Training loss: 0.0488\n",
      "Epoch: 63/100... Training loss: 0.0476\n",
      "Epoch: 63/100... Training loss: 0.0488\n",
      "Epoch: 63/100... Training loss: 0.0488\n",
      "Epoch: 63/100... Training loss: 0.0489\n",
      "Epoch: 63/100... Training loss: 0.0480\n",
      "Epoch: 64/100... Training loss: 0.0478\n",
      "Epoch: 64/100... Training loss: 0.0472\n",
      "Epoch: 64/100... Training loss: 0.0477\n",
      "Epoch: 64/100... Training loss: 0.0475\n",
      "Epoch: 64/100... Training loss: 0.0477\n",
      "Epoch: 64/100... Training loss: 0.0479\n",
      "Epoch: 64/100... Training loss: 0.0479\n",
      "Epoch: 64/100... Training loss: 0.0483\n",
      "Epoch: 64/100... Training loss: 0.0481\n",
      "Epoch: 64/100... Training loss: 0.0475\n",
      "Epoch: 64/100... Training loss: 0.0481\n",
      "Epoch: 64/100... Training loss: 0.0463\n",
      "Epoch: 64/100... Training loss: 0.0482\n",
      "Epoch: 64/100... Training loss: 0.0488\n",
      "Epoch: 64/100... Training loss: 0.0474\n",
      "Epoch: 64/100... Training loss: 0.0477\n",
      "Epoch: 64/100... Training loss: 0.0483\n",
      "Epoch: 64/100... Training loss: 0.0483\n",
      "Epoch: 64/100... Training loss: 0.0470\n",
      "Epoch: 64/100... Training loss: 0.0483\n",
      "Epoch: 64/100... Training loss: 0.0476\n",
      "Epoch: 65/100... Training loss: 0.0477\n",
      "Epoch: 65/100... Training loss: 0.0473\n",
      "Epoch: 65/100... Training loss: 0.0479\n",
      "Epoch: 65/100... Training loss: 0.0473\n",
      "Epoch: 65/100... Training loss: 0.0475\n",
      "Epoch: 65/100... Training loss: 0.0488\n",
      "Epoch: 65/100... Training loss: 0.0482\n",
      "Epoch: 65/100... Training loss: 0.0468\n",
      "Epoch: 65/100... Training loss: 0.0471\n",
      "Epoch: 65/100... Training loss: 0.0486\n",
      "Epoch: 65/100... Training loss: 0.0480\n",
      "Epoch: 65/100... Training loss: 0.0476\n",
      "Epoch: 65/100... Training loss: 0.0476\n",
      "Epoch: 65/100... Training loss: 0.0481\n",
      "Epoch: 65/100... Training loss: 0.0486\n",
      "Epoch: 65/100... Training loss: 0.0486\n",
      "Epoch: 65/100... Training loss: 0.0475\n",
      "Epoch: 65/100... Training loss: 0.0474\n",
      "Epoch: 65/100... Training loss: 0.0481\n",
      "Epoch: 65/100... Training loss: 0.0476\n",
      "Epoch: 65/100... Training loss: 0.0472\n",
      "Epoch: 66/100... Training loss: 0.0473\n",
      "Epoch: 66/100... Training loss: 0.0479\n",
      "Epoch: 66/100... Training loss: 0.0475\n",
      "Epoch: 66/100... Training loss: 0.0472\n",
      "Epoch: 66/100... Training loss: 0.0478\n",
      "Epoch: 66/100... Training loss: 0.0477\n",
      "Epoch: 66/100... Training loss: 0.0476\n",
      "Epoch: 66/100... Training loss: 0.0469\n",
      "Epoch: 66/100... Training loss: 0.0476\n",
      "Epoch: 66/100... Training loss: 0.0475\n",
      "Epoch: 66/100... Training loss: 0.0469\n",
      "Epoch: 66/100... Training loss: 0.0472\n",
      "Epoch: 66/100... Training loss: 0.0474\n",
      "Epoch: 66/100... Training loss: 0.0473\n",
      "Epoch: 66/100... Training loss: 0.0476\n",
      "Epoch: 66/100... Training loss: 0.0477\n",
      "Epoch: 66/100... Training loss: 0.0477\n",
      "Epoch: 66/100... Training loss: 0.0470\n",
      "Epoch: 66/100... Training loss: 0.0474\n",
      "Epoch: 66/100... Training loss: 0.0470\n",
      "Epoch: 66/100... Training loss: 0.0471\n",
      "Epoch: 67/100... Training loss: 0.0473\n",
      "Epoch: 67/100... Training loss: 0.0473\n",
      "Epoch: 67/100... Training loss: 0.0485\n",
      "Epoch: 67/100... Training loss: 0.0480\n",
      "Epoch: 67/100... Training loss: 0.0473\n",
      "Epoch: 67/100... Training loss: 0.0472\n",
      "Epoch: 67/100... Training loss: 0.0474\n",
      "Epoch: 67/100... Training loss: 0.0477\n",
      "Epoch: 67/100... Training loss: 0.0460\n",
      "Epoch: 67/100... Training loss: 0.0470\n",
      "Epoch: 67/100... Training loss: 0.0481\n",
      "Epoch: 67/100... Training loss: 0.0479\n",
      "Epoch: 67/100... Training loss: 0.0476\n",
      "Epoch: 67/100... Training loss: 0.0476\n",
      "Epoch: 67/100... Training loss: 0.0487\n",
      "Epoch: 67/100... Training loss: 0.0476\n",
      "Epoch: 67/100... Training loss: 0.0477\n",
      "Epoch: 67/100... Training loss: 0.0478\n",
      "Epoch: 67/100... Training loss: 0.0480\n",
      "Epoch: 67/100... Training loss: 0.0478\n",
      "Epoch: 67/100... Training loss: 0.0478\n",
      "Epoch: 68/100... Training loss: 0.0481\n",
      "Epoch: 68/100... Training loss: 0.0477\n",
      "Epoch: 68/100... Training loss: 0.0465\n",
      "Epoch: 68/100... Training loss: 0.0478\n",
      "Epoch: 68/100... Training loss: 0.0477\n",
      "Epoch: 68/100... Training loss: 0.0472\n",
      "Epoch: 68/100... Training loss: 0.0473\n",
      "Epoch: 68/100... Training loss: 0.0474\n",
      "Epoch: 68/100... Training loss: 0.0468\n",
      "Epoch: 68/100... Training loss: 0.0480\n",
      "Epoch: 68/100... Training loss: 0.0477\n",
      "Epoch: 68/100... Training loss: 0.0482\n",
      "Epoch: 68/100... Training loss: 0.0473\n",
      "Epoch: 68/100... Training loss: 0.0476\n",
      "Epoch: 68/100... Training loss: 0.0481\n",
      "Epoch: 68/100... Training loss: 0.0472\n",
      "Epoch: 68/100... Training loss: 0.0479\n",
      "Epoch: 68/100... Training loss: 0.0473\n",
      "Epoch: 68/100... Training loss: 0.0475\n",
      "Epoch: 68/100... Training loss: 0.0477\n",
      "Epoch: 68/100... Training loss: 0.0474\n",
      "Epoch: 69/100... Training loss: 0.0464\n",
      "Epoch: 69/100... Training loss: 0.0482\n",
      "Epoch: 69/100... Training loss: 0.0476\n",
      "Epoch: 69/100... Training loss: 0.0470\n",
      "Epoch: 69/100... Training loss: 0.0477\n",
      "Epoch: 69/100... Training loss: 0.0475\n",
      "Epoch: 69/100... Training loss: 0.0472\n",
      "Epoch: 69/100... Training loss: 0.0474\n",
      "Epoch: 69/100... Training loss: 0.0471\n",
      "Epoch: 69/100... Training loss: 0.0475\n",
      "Epoch: 69/100... Training loss: 0.0482\n",
      "Epoch: 69/100... Training loss: 0.0477\n",
      "Epoch: 69/100... Training loss: 0.0479\n",
      "Epoch: 69/100... Training loss: 0.0472\n",
      "Epoch: 69/100... Training loss: 0.0469\n",
      "Epoch: 69/100... Training loss: 0.0465\n",
      "Epoch: 69/100... Training loss: 0.0474\n",
      "Epoch: 69/100... Training loss: 0.0474\n",
      "Epoch: 69/100... Training loss: 0.0472\n",
      "Epoch: 69/100... Training loss: 0.0468\n",
      "Epoch: 69/100... Training loss: 0.0471\n",
      "Epoch: 70/100... Training loss: 0.0473\n",
      "Epoch: 70/100... Training loss: 0.0462\n",
      "Epoch: 70/100... Training loss: 0.0480\n",
      "Epoch: 70/100... Training loss: 0.0471\n",
      "Epoch: 70/100... Training loss: 0.0474\n",
      "Epoch: 70/100... Training loss: 0.0469\n",
      "Epoch: 70/100... Training loss: 0.0467\n",
      "Epoch: 70/100... Training loss: 0.0475\n",
      "Epoch: 70/100... Training loss: 0.0476\n",
      "Epoch: 70/100... Training loss: 0.0473\n",
      "Epoch: 70/100... Training loss: 0.0479\n",
      "Epoch: 70/100... Training loss: 0.0476\n",
      "Epoch: 70/100... Training loss: 0.0482\n",
      "Epoch: 70/100... Training loss: 0.0481\n",
      "Epoch: 70/100... Training loss: 0.0480\n",
      "Epoch: 70/100... Training loss: 0.0478\n",
      "Epoch: 70/100... Training loss: 0.0470\n",
      "Epoch: 70/100... Training loss: 0.0474\n",
      "Epoch: 70/100... Training loss: 0.0480\n",
      "Epoch: 70/100... Training loss: 0.0474\n",
      "Epoch: 70/100... Training loss: 0.0472\n",
      "Epoch: 71/100... Training loss: 0.0476\n",
      "Epoch: 71/100... Training loss: 0.0471\n",
      "Epoch: 71/100... Training loss: 0.0469\n",
      "Epoch: 71/100... Training loss: 0.0474\n",
      "Epoch: 71/100... Training loss: 0.0482\n",
      "Epoch: 71/100... Training loss: 0.0481\n",
      "Epoch: 71/100... Training loss: 0.0477\n",
      "Epoch: 71/100... Training loss: 0.0477\n",
      "Epoch: 71/100... Training loss: 0.0480\n",
      "Epoch: 71/100... Training loss: 0.0469\n",
      "Epoch: 71/100... Training loss: 0.0476\n",
      "Epoch: 71/100... Training loss: 0.0478\n",
      "Epoch: 71/100... Training loss: 0.0475\n",
      "Epoch: 71/100... Training loss: 0.0469\n",
      "Epoch: 71/100... Training loss: 0.0472\n",
      "Epoch: 71/100... Training loss: 0.0471\n",
      "Epoch: 71/100... Training loss: 0.0476\n",
      "Epoch: 71/100... Training loss: 0.0479\n",
      "Epoch: 71/100... Training loss: 0.0471\n",
      "Epoch: 71/100... Training loss: 0.0459\n",
      "Epoch: 71/100... Training loss: 0.0479\n",
      "Epoch: 72/100... Training loss: 0.0467\n",
      "Epoch: 72/100... Training loss: 0.0474\n",
      "Epoch: 72/100... Training loss: 0.0473\n",
      "Epoch: 72/100... Training loss: 0.0466\n",
      "Epoch: 72/100... Training loss: 0.0478\n",
      "Epoch: 72/100... Training loss: 0.0469\n",
      "Epoch: 72/100... Training loss: 0.0476\n",
      "Epoch: 72/100... Training loss: 0.0466\n",
      "Epoch: 72/100... Training loss: 0.0471\n",
      "Epoch: 72/100... Training loss: 0.0481\n",
      "Epoch: 72/100... Training loss: 0.0474\n",
      "Epoch: 72/100... Training loss: 0.0483\n",
      "Epoch: 72/100... Training loss: 0.0476\n",
      "Epoch: 72/100... Training loss: 0.0483\n",
      "Epoch: 72/100... Training loss: 0.0472\n",
      "Epoch: 72/100... Training loss: 0.0471\n",
      "Epoch: 72/100... Training loss: 0.0467\n",
      "Epoch: 72/100... Training loss: 0.0470\n",
      "Epoch: 72/100... Training loss: 0.0478\n",
      "Epoch: 72/100... Training loss: 0.0474\n",
      "Epoch: 72/100... Training loss: 0.0467\n",
      "Epoch: 73/100... Training loss: 0.0463\n",
      "Epoch: 73/100... Training loss: 0.0474\n",
      "Epoch: 73/100... Training loss: 0.0464\n",
      "Epoch: 73/100... Training loss: 0.0463\n",
      "Epoch: 73/100... Training loss: 0.0483\n",
      "Epoch: 73/100... Training loss: 0.0469\n",
      "Epoch: 73/100... Training loss: 0.0471\n",
      "Epoch: 73/100... Training loss: 0.0479\n",
      "Epoch: 73/100... Training loss: 0.0466\n",
      "Epoch: 73/100... Training loss: 0.0476\n",
      "Epoch: 73/100... Training loss: 0.0477\n",
      "Epoch: 73/100... Training loss: 0.0470\n",
      "Epoch: 73/100... Training loss: 0.0473\n",
      "Epoch: 73/100... Training loss: 0.0472\n",
      "Epoch: 73/100... Training loss: 0.0468\n",
      "Epoch: 73/100... Training loss: 0.0473\n",
      "Epoch: 73/100... Training loss: 0.0471\n",
      "Epoch: 73/100... Training loss: 0.0483\n",
      "Epoch: 73/100... Training loss: 0.0471\n",
      "Epoch: 73/100... Training loss: 0.0473\n",
      "Epoch: 73/100... Training loss: 0.0475\n",
      "Epoch: 74/100... Training loss: 0.0468\n",
      "Epoch: 74/100... Training loss: 0.0470\n",
      "Epoch: 74/100... Training loss: 0.0470\n",
      "Epoch: 74/100... Training loss: 0.0476\n",
      "Epoch: 74/100... Training loss: 0.0479\n",
      "Epoch: 74/100... Training loss: 0.0470\n",
      "Epoch: 74/100... Training loss: 0.0475\n",
      "Epoch: 74/100... Training loss: 0.0469\n",
      "Epoch: 74/100... Training loss: 0.0469\n",
      "Epoch: 74/100... Training loss: 0.0464\n",
      "Epoch: 74/100... Training loss: 0.0470\n",
      "Epoch: 74/100... Training loss: 0.0469\n",
      "Epoch: 74/100... Training loss: 0.0470\n",
      "Epoch: 74/100... Training loss: 0.0470\n",
      "Epoch: 74/100... Training loss: 0.0465\n",
      "Epoch: 74/100... Training loss: 0.0475\n",
      "Epoch: 74/100... Training loss: 0.0463\n",
      "Epoch: 74/100... Training loss: 0.0470\n",
      "Epoch: 74/100... Training loss: 0.0465\n",
      "Epoch: 74/100... Training loss: 0.0458\n",
      "Epoch: 74/100... Training loss: 0.0465\n",
      "Epoch: 75/100... Training loss: 0.0468\n",
      "Epoch: 75/100... Training loss: 0.0470\n",
      "Epoch: 75/100... Training loss: 0.0473\n",
      "Epoch: 75/100... Training loss: 0.0472\n",
      "Epoch: 75/100... Training loss: 0.0468\n",
      "Epoch: 75/100... Training loss: 0.0467\n",
      "Epoch: 75/100... Training loss: 0.0478\n",
      "Epoch: 75/100... Training loss: 0.0471\n",
      "Epoch: 75/100... Training loss: 0.0476\n",
      "Epoch: 75/100... Training loss: 0.0466\n",
      "Epoch: 75/100... Training loss: 0.0466\n",
      "Epoch: 75/100... Training loss: 0.0475\n",
      "Epoch: 75/100... Training loss: 0.0478\n",
      "Epoch: 75/100... Training loss: 0.0458\n",
      "Epoch: 75/100... Training loss: 0.0471\n",
      "Epoch: 75/100... Training loss: 0.0466\n",
      "Epoch: 75/100... Training loss: 0.0482\n",
      "Epoch: 75/100... Training loss: 0.0479\n",
      "Epoch: 75/100... Training loss: 0.0465\n",
      "Epoch: 75/100... Training loss: 0.0469\n",
      "Epoch: 75/100... Training loss: 0.0476\n",
      "Epoch: 76/100... Training loss: 0.0458\n",
      "Epoch: 76/100... Training loss: 0.0475\n",
      "Epoch: 76/100... Training loss: 0.0465\n",
      "Epoch: 76/100... Training loss: 0.0472\n",
      "Epoch: 76/100... Training loss: 0.0472\n",
      "Epoch: 76/100... Training loss: 0.0477\n",
      "Epoch: 76/100... Training loss: 0.0461\n",
      "Epoch: 76/100... Training loss: 0.0465\n",
      "Epoch: 76/100... Training loss: 0.0468\n",
      "Epoch: 76/100... Training loss: 0.0476\n",
      "Epoch: 76/100... Training loss: 0.0468\n",
      "Epoch: 76/100... Training loss: 0.0471\n",
      "Epoch: 76/100... Training loss: 0.0469\n",
      "Epoch: 76/100... Training loss: 0.0465\n",
      "Epoch: 76/100... Training loss: 0.0476\n",
      "Epoch: 76/100... Training loss: 0.0472\n",
      "Epoch: 76/100... Training loss: 0.0473\n",
      "Epoch: 76/100... Training loss: 0.0466\n",
      "Epoch: 76/100... Training loss: 0.0468\n",
      "Epoch: 76/100... Training loss: 0.0478\n",
      "Epoch: 76/100... Training loss: 0.0476\n",
      "Epoch: 77/100... Training loss: 0.0464\n",
      "Epoch: 77/100... Training loss: 0.0471\n",
      "Epoch: 77/100... Training loss: 0.0470\n",
      "Epoch: 77/100... Training loss: 0.0472\n",
      "Epoch: 77/100... Training loss: 0.0473\n",
      "Epoch: 77/100... Training loss: 0.0467\n",
      "Epoch: 77/100... Training loss: 0.0473\n",
      "Epoch: 77/100... Training loss: 0.0475\n",
      "Epoch: 77/100... Training loss: 0.0472\n",
      "Epoch: 77/100... Training loss: 0.0465\n",
      "Epoch: 77/100... Training loss: 0.0474\n",
      "Epoch: 77/100... Training loss: 0.0462\n",
      "Epoch: 77/100... Training loss: 0.0474\n",
      "Epoch: 77/100... Training loss: 0.0458\n",
      "Epoch: 77/100... Training loss: 0.0467\n",
      "Epoch: 77/100... Training loss: 0.0466\n",
      "Epoch: 77/100... Training loss: 0.0459\n",
      "Epoch: 77/100... Training loss: 0.0462\n",
      "Epoch: 77/100... Training loss: 0.0473\n",
      "Epoch: 77/100... Training loss: 0.0466\n",
      "Epoch: 77/100... Training loss: 0.0475\n",
      "Epoch: 78/100... Training loss: 0.0481\n",
      "Epoch: 78/100... Training loss: 0.0462\n",
      "Epoch: 78/100... Training loss: 0.0474\n",
      "Epoch: 78/100... Training loss: 0.0474\n",
      "Epoch: 78/100... Training loss: 0.0471\n",
      "Epoch: 78/100... Training loss: 0.0465\n",
      "Epoch: 78/100... Training loss: 0.0473\n",
      "Epoch: 78/100... Training loss: 0.0468\n",
      "Epoch: 78/100... Training loss: 0.0471\n",
      "Epoch: 78/100... Training loss: 0.0472\n",
      "Epoch: 78/100... Training loss: 0.0471\n",
      "Epoch: 78/100... Training loss: 0.0474\n",
      "Epoch: 78/100... Training loss: 0.0468\n",
      "Epoch: 78/100... Training loss: 0.0463\n",
      "Epoch: 78/100... Training loss: 0.0472\n",
      "Epoch: 78/100... Training loss: 0.0462\n",
      "Epoch: 78/100... Training loss: 0.0460\n",
      "Epoch: 78/100... Training loss: 0.0468\n",
      "Epoch: 78/100... Training loss: 0.0463\n",
      "Epoch: 78/100... Training loss: 0.0469\n",
      "Epoch: 78/100... Training loss: 0.0465\n",
      "Epoch: 79/100... Training loss: 0.0468\n",
      "Epoch: 79/100... Training loss: 0.0464\n",
      "Epoch: 79/100... Training loss: 0.0465\n",
      "Epoch: 79/100... Training loss: 0.0478\n",
      "Epoch: 79/100... Training loss: 0.0468\n",
      "Epoch: 79/100... Training loss: 0.0468\n",
      "Epoch: 79/100... Training loss: 0.0469\n",
      "Epoch: 79/100... Training loss: 0.0480\n",
      "Epoch: 79/100... Training loss: 0.0471\n",
      "Epoch: 79/100... Training loss: 0.0477\n",
      "Epoch: 79/100... Training loss: 0.0477\n",
      "Epoch: 79/100... Training loss: 0.0475\n",
      "Epoch: 79/100... Training loss: 0.0468\n",
      "Epoch: 79/100... Training loss: 0.0470\n",
      "Epoch: 79/100... Training loss: 0.0484\n",
      "Epoch: 79/100... Training loss: 0.0467\n",
      "Epoch: 79/100... Training loss: 0.0472\n",
      "Epoch: 79/100... Training loss: 0.0481\n",
      "Epoch: 79/100... Training loss: 0.0471\n",
      "Epoch: 79/100... Training loss: 0.0474\n",
      "Epoch: 79/100... Training loss: 0.0470\n",
      "Epoch: 80/100... Training loss: 0.0472\n",
      "Epoch: 80/100... Training loss: 0.0474\n",
      "Epoch: 80/100... Training loss: 0.0478\n",
      "Epoch: 80/100... Training loss: 0.0472\n",
      "Epoch: 80/100... Training loss: 0.0482\n",
      "Epoch: 80/100... Training loss: 0.0481\n",
      "Epoch: 80/100... Training loss: 0.0466\n",
      "Epoch: 80/100... Training loss: 0.0479\n",
      "Epoch: 80/100... Training loss: 0.0487\n",
      "Epoch: 80/100... Training loss: 0.0469\n",
      "Epoch: 80/100... Training loss: 0.0489\n",
      "Epoch: 80/100... Training loss: 0.0499\n",
      "Epoch: 80/100... Training loss: 0.0482\n",
      "Epoch: 80/100... Training loss: 0.0505\n",
      "Epoch: 80/100... Training loss: 0.0488\n",
      "Epoch: 80/100... Training loss: 0.0491\n",
      "Epoch: 80/100... Training loss: 0.0482\n",
      "Epoch: 80/100... Training loss: 0.0478\n",
      "Epoch: 80/100... Training loss: 0.0473\n",
      "Epoch: 80/100... Training loss: 0.0478\n",
      "Epoch: 80/100... Training loss: 0.0474\n",
      "Epoch: 81/100... Training loss: 0.0472\n",
      "Epoch: 81/100... Training loss: 0.0479\n",
      "Epoch: 81/100... Training loss: 0.0486\n",
      "Epoch: 81/100... Training loss: 0.0478\n",
      "Epoch: 81/100... Training loss: 0.0482\n",
      "Epoch: 81/100... Training loss: 0.0470\n",
      "Epoch: 81/100... Training loss: 0.0481\n",
      "Epoch: 81/100... Training loss: 0.0478\n",
      "Epoch: 81/100... Training loss: 0.0477\n",
      "Epoch: 81/100... Training loss: 0.0468\n",
      "Epoch: 81/100... Training loss: 0.0477\n",
      "Epoch: 81/100... Training loss: 0.0472\n",
      "Epoch: 81/100... Training loss: 0.0454\n",
      "Epoch: 81/100... Training loss: 0.0477\n",
      "Epoch: 81/100... Training loss: 0.0463\n",
      "Epoch: 81/100... Training loss: 0.0468\n",
      "Epoch: 81/100... Training loss: 0.0475\n",
      "Epoch: 81/100... Training loss: 0.0470\n",
      "Epoch: 81/100... Training loss: 0.0473\n",
      "Epoch: 81/100... Training loss: 0.0466\n",
      "Epoch: 81/100... Training loss: 0.0474\n",
      "Epoch: 82/100... Training loss: 0.0466\n",
      "Epoch: 82/100... Training loss: 0.0470\n",
      "Epoch: 82/100... Training loss: 0.0478\n",
      "Epoch: 82/100... Training loss: 0.0470\n",
      "Epoch: 82/100... Training loss: 0.0469\n",
      "Epoch: 82/100... Training loss: 0.0471\n",
      "Epoch: 82/100... Training loss: 0.0473\n",
      "Epoch: 82/100... Training loss: 0.0469\n",
      "Epoch: 82/100... Training loss: 0.0469\n",
      "Epoch: 82/100... Training loss: 0.0462\n",
      "Epoch: 82/100... Training loss: 0.0463\n",
      "Epoch: 82/100... Training loss: 0.0455\n",
      "Epoch: 82/100... Training loss: 0.0462\n",
      "Epoch: 82/100... Training loss: 0.0465\n",
      "Epoch: 82/100... Training loss: 0.0465\n",
      "Epoch: 82/100... Training loss: 0.0460\n",
      "Epoch: 82/100... Training loss: 0.0467\n",
      "Epoch: 82/100... Training loss: 0.0470\n",
      "Epoch: 82/100... Training loss: 0.0465\n",
      "Epoch: 82/100... Training loss: 0.0458\n",
      "Epoch: 82/100... Training loss: 0.0469\n",
      "Epoch: 83/100... Training loss: 0.0465\n",
      "Epoch: 83/100... Training loss: 0.0469\n",
      "Epoch: 83/100... Training loss: 0.0459\n",
      "Epoch: 83/100... Training loss: 0.0465\n",
      "Epoch: 83/100... Training loss: 0.0465\n",
      "Epoch: 83/100... Training loss: 0.0463\n",
      "Epoch: 83/100... Training loss: 0.0471\n",
      "Epoch: 83/100... Training loss: 0.0462\n",
      "Epoch: 83/100... Training loss: 0.0467\n",
      "Epoch: 83/100... Training loss: 0.0461\n",
      "Epoch: 83/100... Training loss: 0.0471\n",
      "Epoch: 83/100... Training loss: 0.0468\n",
      "Epoch: 83/100... Training loss: 0.0473\n",
      "Epoch: 83/100... Training loss: 0.0476\n",
      "Epoch: 83/100... Training loss: 0.0470\n",
      "Epoch: 83/100... Training loss: 0.0462\n",
      "Epoch: 83/100... Training loss: 0.0459\n",
      "Epoch: 83/100... Training loss: 0.0458\n",
      "Epoch: 83/100... Training loss: 0.0476\n",
      "Epoch: 83/100... Training loss: 0.0460\n",
      "Epoch: 83/100... Training loss: 0.0464\n",
      "Epoch: 84/100... Training loss: 0.0461\n",
      "Epoch: 84/100... Training loss: 0.0463\n",
      "Epoch: 84/100... Training loss: 0.0459\n",
      "Epoch: 84/100... Training loss: 0.0469\n",
      "Epoch: 84/100... Training loss: 0.0468\n",
      "Epoch: 84/100... Training loss: 0.0469\n",
      "Epoch: 84/100... Training loss: 0.0454\n",
      "Epoch: 84/100... Training loss: 0.0470\n",
      "Epoch: 84/100... Training loss: 0.0466\n",
      "Epoch: 84/100... Training loss: 0.0471\n",
      "Epoch: 84/100... Training loss: 0.0465\n",
      "Epoch: 84/100... Training loss: 0.0462\n",
      "Epoch: 84/100... Training loss: 0.0462\n",
      "Epoch: 84/100... Training loss: 0.0477\n",
      "Epoch: 84/100... Training loss: 0.0465\n",
      "Epoch: 84/100... Training loss: 0.0482\n",
      "Epoch: 84/100... Training loss: 0.0466\n",
      "Epoch: 84/100... Training loss: 0.0466\n",
      "Epoch: 84/100... Training loss: 0.0464\n",
      "Epoch: 84/100... Training loss: 0.0465\n",
      "Epoch: 84/100... Training loss: 0.0470\n",
      "Epoch: 85/100... Training loss: 0.0463\n",
      "Epoch: 85/100... Training loss: 0.0473\n",
      "Epoch: 85/100... Training loss: 0.0459\n",
      "Epoch: 85/100... Training loss: 0.0465\n",
      "Epoch: 85/100... Training loss: 0.0457\n",
      "Epoch: 85/100... Training loss: 0.0467\n",
      "Epoch: 85/100... Training loss: 0.0465\n",
      "Epoch: 85/100... Training loss: 0.0473\n",
      "Epoch: 85/100... Training loss: 0.0459\n",
      "Epoch: 85/100... Training loss: 0.0468\n",
      "Epoch: 85/100... Training loss: 0.0472\n",
      "Epoch: 85/100... Training loss: 0.0474\n",
      "Epoch: 85/100... Training loss: 0.0455\n",
      "Epoch: 85/100... Training loss: 0.0474\n",
      "Epoch: 85/100... Training loss: 0.0472\n",
      "Epoch: 85/100... Training loss: 0.0470\n",
      "Epoch: 85/100... Training loss: 0.0470\n",
      "Epoch: 85/100... Training loss: 0.0466\n",
      "Epoch: 85/100... Training loss: 0.0466\n",
      "Epoch: 85/100... Training loss: 0.0467\n",
      "Epoch: 85/100... Training loss: 0.0465\n",
      "Epoch: 86/100... Training loss: 0.0474\n",
      "Epoch: 86/100... Training loss: 0.0462\n",
      "Epoch: 86/100... Training loss: 0.0469\n",
      "Epoch: 86/100... Training loss: 0.0475\n",
      "Epoch: 86/100... Training loss: 0.0465\n",
      "Epoch: 86/100... Training loss: 0.0468\n",
      "Epoch: 86/100... Training loss: 0.0465\n",
      "Epoch: 86/100... Training loss: 0.0462\n",
      "Epoch: 86/100... Training loss: 0.0458\n",
      "Epoch: 86/100... Training loss: 0.0457\n",
      "Epoch: 86/100... Training loss: 0.0468\n",
      "Epoch: 86/100... Training loss: 0.0468\n",
      "Epoch: 86/100... Training loss: 0.0461\n",
      "Epoch: 86/100... Training loss: 0.0460\n",
      "Epoch: 86/100... Training loss: 0.0464\n",
      "Epoch: 86/100... Training loss: 0.0467\n",
      "Epoch: 86/100... Training loss: 0.0459\n",
      "Epoch: 86/100... Training loss: 0.0461\n",
      "Epoch: 86/100... Training loss: 0.0476\n",
      "Epoch: 86/100... Training loss: 0.0469\n",
      "Epoch: 86/100... Training loss: 0.0466\n",
      "Epoch: 87/100... Training loss: 0.0463\n",
      "Epoch: 87/100... Training loss: 0.0477\n",
      "Epoch: 87/100... Training loss: 0.0464\n",
      "Epoch: 87/100... Training loss: 0.0459\n",
      "Epoch: 87/100... Training loss: 0.0466\n",
      "Epoch: 87/100... Training loss: 0.0460\n",
      "Epoch: 87/100... Training loss: 0.0460\n",
      "Epoch: 87/100... Training loss: 0.0455\n",
      "Epoch: 87/100... Training loss: 0.0465\n",
      "Epoch: 87/100... Training loss: 0.0462\n",
      "Epoch: 87/100... Training loss: 0.0466\n",
      "Epoch: 87/100... Training loss: 0.0461\n",
      "Epoch: 87/100... Training loss: 0.0473\n",
      "Epoch: 87/100... Training loss: 0.0467\n",
      "Epoch: 87/100... Training loss: 0.0471\n",
      "Epoch: 87/100... Training loss: 0.0458\n",
      "Epoch: 87/100... Training loss: 0.0456\n",
      "Epoch: 87/100... Training loss: 0.0469\n",
      "Epoch: 87/100... Training loss: 0.0464\n",
      "Epoch: 87/100... Training loss: 0.0463\n",
      "Epoch: 87/100... Training loss: 0.0470\n",
      "Epoch: 88/100... Training loss: 0.0466\n",
      "Epoch: 88/100... Training loss: 0.0468\n",
      "Epoch: 88/100... Training loss: 0.0463\n",
      "Epoch: 88/100... Training loss: 0.0466\n",
      "Epoch: 88/100... Training loss: 0.0458\n",
      "Epoch: 88/100... Training loss: 0.0463\n",
      "Epoch: 88/100... Training loss: 0.0468\n",
      "Epoch: 88/100... Training loss: 0.0458\n",
      "Epoch: 88/100... Training loss: 0.0461\n",
      "Epoch: 88/100... Training loss: 0.0462\n",
      "Epoch: 88/100... Training loss: 0.0460\n",
      "Epoch: 88/100... Training loss: 0.0458\n",
      "Epoch: 88/100... Training loss: 0.0462\n",
      "Epoch: 88/100... Training loss: 0.0470\n",
      "Epoch: 88/100... Training loss: 0.0458\n",
      "Epoch: 88/100... Training loss: 0.0467\n",
      "Epoch: 88/100... Training loss: 0.0460\n",
      "Epoch: 88/100... Training loss: 0.0467\n",
      "Epoch: 88/100... Training loss: 0.0466\n",
      "Epoch: 88/100... Training loss: 0.0459\n",
      "Epoch: 88/100... Training loss: 0.0464\n",
      "Epoch: 89/100... Training loss: 0.0456\n",
      "Epoch: 89/100... Training loss: 0.0472\n",
      "Epoch: 89/100... Training loss: 0.0472\n",
      "Epoch: 89/100... Training loss: 0.0466\n",
      "Epoch: 89/100... Training loss: 0.0471\n",
      "Epoch: 89/100... Training loss: 0.0467\n",
      "Epoch: 89/100... Training loss: 0.0462\n",
      "Epoch: 89/100... Training loss: 0.0469\n",
      "Epoch: 89/100... Training loss: 0.0464\n",
      "Epoch: 89/100... Training loss: 0.0477\n",
      "Epoch: 89/100... Training loss: 0.0470\n",
      "Epoch: 89/100... Training loss: 0.0470\n",
      "Epoch: 89/100... Training loss: 0.0469\n",
      "Epoch: 89/100... Training loss: 0.0459\n",
      "Epoch: 89/100... Training loss: 0.0465\n",
      "Epoch: 89/100... Training loss: 0.0467\n",
      "Epoch: 89/100... Training loss: 0.0466\n",
      "Epoch: 89/100... Training loss: 0.0466\n",
      "Epoch: 89/100... Training loss: 0.0462\n",
      "Epoch: 89/100... Training loss: 0.0463\n",
      "Epoch: 89/100... Training loss: 0.0469\n",
      "Epoch: 90/100... Training loss: 0.0459\n",
      "Epoch: 90/100... Training loss: 0.0459\n",
      "Epoch: 90/100... Training loss: 0.0454\n",
      "Epoch: 90/100... Training loss: 0.0463\n",
      "Epoch: 90/100... Training loss: 0.0468\n",
      "Epoch: 90/100... Training loss: 0.0461\n",
      "Epoch: 90/100... Training loss: 0.0466\n",
      "Epoch: 90/100... Training loss: 0.0471\n",
      "Epoch: 90/100... Training loss: 0.0462\n",
      "Epoch: 90/100... Training loss: 0.0457\n",
      "Epoch: 90/100... Training loss: 0.0459\n",
      "Epoch: 90/100... Training loss: 0.0458\n",
      "Epoch: 90/100... Training loss: 0.0468\n",
      "Epoch: 90/100... Training loss: 0.0461\n",
      "Epoch: 90/100... Training loss: 0.0463\n",
      "Epoch: 90/100... Training loss: 0.0467\n",
      "Epoch: 90/100... Training loss: 0.0466\n",
      "Epoch: 90/100... Training loss: 0.0458\n",
      "Epoch: 90/100... Training loss: 0.0461\n",
      "Epoch: 90/100... Training loss: 0.0463\n",
      "Epoch: 90/100... Training loss: 0.0459\n",
      "Epoch: 91/100... Training loss: 0.0476\n",
      "Epoch: 91/100... Training loss: 0.0465\n",
      "Epoch: 91/100... Training loss: 0.0463\n",
      "Epoch: 91/100... Training loss: 0.0458\n",
      "Epoch: 91/100... Training loss: 0.0466\n",
      "Epoch: 91/100... Training loss: 0.0466\n",
      "Epoch: 91/100... Training loss: 0.0453\n",
      "Epoch: 91/100... Training loss: 0.0462\n",
      "Epoch: 91/100... Training loss: 0.0464\n",
      "Epoch: 91/100... Training loss: 0.0460\n",
      "Epoch: 91/100... Training loss: 0.0461\n",
      "Epoch: 91/100... Training loss: 0.0466\n",
      "Epoch: 91/100... Training loss: 0.0463\n",
      "Epoch: 91/100... Training loss: 0.0465\n",
      "Epoch: 91/100... Training loss: 0.0457\n",
      "Epoch: 91/100... Training loss: 0.0455\n",
      "Epoch: 91/100... Training loss: 0.0459\n",
      "Epoch: 91/100... Training loss: 0.0461\n",
      "Epoch: 91/100... Training loss: 0.0463\n",
      "Epoch: 91/100... Training loss: 0.0469\n",
      "Epoch: 91/100... Training loss: 0.0461\n",
      "Epoch: 92/100... Training loss: 0.0466\n",
      "Epoch: 92/100... Training loss: 0.0465\n",
      "Epoch: 92/100... Training loss: 0.0476\n",
      "Epoch: 92/100... Training loss: 0.0480\n",
      "Epoch: 92/100... Training loss: 0.0477\n",
      "Epoch: 92/100... Training loss: 0.0469\n",
      "Epoch: 92/100... Training loss: 0.0455\n",
      "Epoch: 92/100... Training loss: 0.0466\n",
      "Epoch: 92/100... Training loss: 0.0471\n",
      "Epoch: 92/100... Training loss: 0.0463\n",
      "Epoch: 92/100... Training loss: 0.0466\n",
      "Epoch: 92/100... Training loss: 0.0458\n",
      "Epoch: 92/100... Training loss: 0.0465\n",
      "Epoch: 92/100... Training loss: 0.0461\n",
      "Epoch: 92/100... Training loss: 0.0462\n",
      "Epoch: 92/100... Training loss: 0.0465\n",
      "Epoch: 92/100... Training loss: 0.0459\n",
      "Epoch: 92/100... Training loss: 0.0466\n",
      "Epoch: 92/100... Training loss: 0.0475\n",
      "Epoch: 92/100... Training loss: 0.0455\n",
      "Epoch: 92/100... Training loss: 0.0460\n",
      "Epoch: 93/100... Training loss: 0.0461\n",
      "Epoch: 93/100... Training loss: 0.0458\n",
      "Epoch: 93/100... Training loss: 0.0468\n",
      "Epoch: 93/100... Training loss: 0.0464\n",
      "Epoch: 93/100... Training loss: 0.0468\n",
      "Epoch: 93/100... Training loss: 0.0465\n",
      "Epoch: 93/100... Training loss: 0.0466\n",
      "Epoch: 93/100... Training loss: 0.0465\n",
      "Epoch: 93/100... Training loss: 0.0457\n",
      "Epoch: 93/100... Training loss: 0.0462\n",
      "Epoch: 93/100... Training loss: 0.0461\n",
      "Epoch: 93/100... Training loss: 0.0462\n",
      "Epoch: 93/100... Training loss: 0.0456\n",
      "Epoch: 93/100... Training loss: 0.0457\n",
      "Epoch: 93/100... Training loss: 0.0467\n",
      "Epoch: 93/100... Training loss: 0.0464\n",
      "Epoch: 93/100... Training loss: 0.0461\n",
      "Epoch: 93/100... Training loss: 0.0458\n",
      "Epoch: 93/100... Training loss: 0.0470\n",
      "Epoch: 93/100... Training loss: 0.0467\n",
      "Epoch: 93/100... Training loss: 0.0470\n",
      "Epoch: 94/100... Training loss: 0.0468\n",
      "Epoch: 94/100... Training loss: 0.0464\n",
      "Epoch: 94/100... Training loss: 0.0468\n",
      "Epoch: 94/100... Training loss: 0.0454\n",
      "Epoch: 94/100... Training loss: 0.0464\n",
      "Epoch: 94/100... Training loss: 0.0466\n",
      "Epoch: 94/100... Training loss: 0.0453\n",
      "Epoch: 94/100... Training loss: 0.0467\n",
      "Epoch: 94/100... Training loss: 0.0460\n",
      "Epoch: 94/100... Training loss: 0.0470\n",
      "Epoch: 94/100... Training loss: 0.0464\n",
      "Epoch: 94/100... Training loss: 0.0461\n",
      "Epoch: 94/100... Training loss: 0.0462\n",
      "Epoch: 94/100... Training loss: 0.0462\n",
      "Epoch: 94/100... Training loss: 0.0460\n",
      "Epoch: 94/100... Training loss: 0.0464\n",
      "Epoch: 94/100... Training loss: 0.0461\n",
      "Epoch: 94/100... Training loss: 0.0466\n",
      "Epoch: 94/100... Training loss: 0.0463\n",
      "Epoch: 94/100... Training loss: 0.0460\n",
      "Epoch: 94/100... Training loss: 0.0459\n",
      "Epoch: 95/100... Training loss: 0.0454\n",
      "Epoch: 95/100... Training loss: 0.0452\n",
      "Epoch: 95/100... Training loss: 0.0468\n",
      "Epoch: 95/100... Training loss: 0.0468\n",
      "Epoch: 95/100... Training loss: 0.0456\n",
      "Epoch: 95/100... Training loss: 0.0463\n",
      "Epoch: 95/100... Training loss: 0.0463\n",
      "Epoch: 95/100... Training loss: 0.0460\n",
      "Epoch: 95/100... Training loss: 0.0458\n",
      "Epoch: 95/100... Training loss: 0.0456\n",
      "Epoch: 95/100... Training loss: 0.0448\n",
      "Epoch: 95/100... Training loss: 0.0459\n",
      "Epoch: 95/100... Training loss: 0.0460\n",
      "Epoch: 95/100... Training loss: 0.0459\n",
      "Epoch: 95/100... Training loss: 0.0453\n",
      "Epoch: 95/100... Training loss: 0.0459\n",
      "Epoch: 95/100... Training loss: 0.0452\n",
      "Epoch: 95/100... Training loss: 0.0462\n",
      "Epoch: 95/100... Training loss: 0.0459\n",
      "Epoch: 95/100... Training loss: 0.0457\n",
      "Epoch: 95/100... Training loss: 0.0461\n",
      "Epoch: 96/100... Training loss: 0.0461\n",
      "Epoch: 96/100... Training loss: 0.0462\n",
      "Epoch: 96/100... Training loss: 0.0461\n",
      "Epoch: 96/100... Training loss: 0.0471\n",
      "Epoch: 96/100... Training loss: 0.0487\n",
      "Epoch: 96/100... Training loss: 0.0504\n",
      "Epoch: 96/100... Training loss: 0.0553\n",
      "Epoch: 96/100... Training loss: 0.0495\n",
      "Epoch: 96/100... Training loss: 0.0468\n",
      "Epoch: 96/100... Training loss: 0.0477\n",
      "Epoch: 96/100... Training loss: 0.0465\n",
      "Epoch: 96/100... Training loss: 0.0485\n",
      "Epoch: 96/100... Training loss: 0.0476\n",
      "Epoch: 96/100... Training loss: 0.0472\n",
      "Epoch: 96/100... Training loss: 0.0476\n",
      "Epoch: 96/100... Training loss: 0.0480\n",
      "Epoch: 96/100... Training loss: 0.0473\n",
      "Epoch: 96/100... Training loss: 0.0477\n",
      "Epoch: 96/100... Training loss: 0.0472\n",
      "Epoch: 96/100... Training loss: 0.0483\n",
      "Epoch: 96/100... Training loss: 0.0477\n",
      "Epoch: 97/100... Training loss: 0.0466\n",
      "Epoch: 97/100... Training loss: 0.0473\n",
      "Epoch: 97/100... Training loss: 0.0469\n",
      "Epoch: 97/100... Training loss: 0.0463\n",
      "Epoch: 97/100... Training loss: 0.0476\n",
      "Epoch: 97/100... Training loss: 0.0465\n",
      "Epoch: 97/100... Training loss: 0.0464\n",
      "Epoch: 97/100... Training loss: 0.0465\n",
      "Epoch: 97/100... Training loss: 0.0462\n",
      "Epoch: 97/100... Training loss: 0.0463\n",
      "Epoch: 97/100... Training loss: 0.0471\n",
      "Epoch: 97/100... Training loss: 0.0469\n",
      "Epoch: 97/100... Training loss: 0.0471\n",
      "Epoch: 97/100... Training loss: 0.0461\n",
      "Epoch: 97/100... Training loss: 0.0460\n",
      "Epoch: 97/100... Training loss: 0.0454\n",
      "Epoch: 97/100... Training loss: 0.0464\n",
      "Epoch: 97/100... Training loss: 0.0467\n",
      "Epoch: 97/100... Training loss: 0.0447\n",
      "Epoch: 97/100... Training loss: 0.0468\n",
      "Epoch: 97/100... Training loss: 0.0459\n",
      "Epoch: 98/100... Training loss: 0.0450\n",
      "Epoch: 98/100... Training loss: 0.0456\n",
      "Epoch: 98/100... Training loss: 0.0458\n",
      "Epoch: 98/100... Training loss: 0.0463\n",
      "Epoch: 98/100... Training loss: 0.0452\n",
      "Epoch: 98/100... Training loss: 0.0454\n",
      "Epoch: 98/100... Training loss: 0.0453\n",
      "Epoch: 98/100... Training loss: 0.0470\n",
      "Epoch: 98/100... Training loss: 0.0469\n",
      "Epoch: 98/100... Training loss: 0.0464\n",
      "Epoch: 98/100... Training loss: 0.0460\n",
      "Epoch: 98/100... Training loss: 0.0468\n",
      "Epoch: 98/100... Training loss: 0.0458\n",
      "Epoch: 98/100... Training loss: 0.0462\n",
      "Epoch: 98/100... Training loss: 0.0460\n",
      "Epoch: 98/100... Training loss: 0.0464\n",
      "Epoch: 98/100... Training loss: 0.0464\n",
      "Epoch: 98/100... Training loss: 0.0459\n",
      "Epoch: 98/100... Training loss: 0.0467\n",
      "Epoch: 98/100... Training loss: 0.0452\n",
      "Epoch: 98/100... Training loss: 0.0462\n",
      "Epoch: 99/100... Training loss: 0.0456\n",
      "Epoch: 99/100... Training loss: 0.0456\n",
      "Epoch: 99/100... Training loss: 0.0463\n",
      "Epoch: 99/100... Training loss: 0.0459\n",
      "Epoch: 99/100... Training loss: 0.0456\n",
      "Epoch: 99/100... Training loss: 0.0461\n",
      "Epoch: 99/100... Training loss: 0.0453\n",
      "Epoch: 99/100... Training loss: 0.0452\n",
      "Epoch: 99/100... Training loss: 0.0458\n",
      "Epoch: 99/100... Training loss: 0.0462\n",
      "Epoch: 99/100... Training loss: 0.0457\n",
      "Epoch: 99/100... Training loss: 0.0457\n",
      "Epoch: 99/100... Training loss: 0.0457\n",
      "Epoch: 99/100... Training loss: 0.0466\n",
      "Epoch: 99/100... Training loss: 0.0462\n",
      "Epoch: 99/100... Training loss: 0.0465\n",
      "Epoch: 99/100... Training loss: 0.0460\n",
      "Epoch: 99/100... Training loss: 0.0455\n",
      "Epoch: 99/100... Training loss: 0.0457\n",
      "Epoch: 99/100... Training loss: 0.0467\n",
      "Epoch: 99/100... Training loss: 0.0459\n",
      "Epoch: 100/100... Training loss: 0.0462\n",
      "Epoch: 100/100... Training loss: 0.0460\n",
      "Epoch: 100/100... Training loss: 0.0456\n",
      "Epoch: 100/100... Training loss: 0.0454\n",
      "Epoch: 100/100... Training loss: 0.0453\n",
      "Epoch: 100/100... Training loss: 0.0458\n",
      "Epoch: 100/100... Training loss: 0.0460\n",
      "Epoch: 100/100... Training loss: 0.0461\n",
      "Epoch: 100/100... Training loss: 0.0456\n",
      "Epoch: 100/100... Training loss: 0.0449\n",
      "Epoch: 100/100... Training loss: 0.0460\n",
      "Epoch: 100/100... Training loss: 0.0463\n",
      "Epoch: 100/100... Training loss: 0.0451\n",
      "Epoch: 100/100... Training loss: 0.0457\n",
      "Epoch: 100/100... Training loss: 0.0453\n",
      "Epoch: 100/100... Training loss: 0.0462\n",
      "Epoch: 100/100... Training loss: 0.0450\n",
      "Epoch: 100/100... Training loss: 0.0457\n",
      "Epoch: 100/100... Training loss: 0.0459\n",
      "Epoch: 100/100... Training loss: 0.0472\n",
      "Epoch: 100/100... Training loss: 0.0457\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:2'):    \n",
    "    sess = tf.Session()\n",
    "    epochs = 100\n",
    "    batch_size = 512\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        for i in range(len(x_train)//batch_size):\n",
    "            img_batch = next_batch(batch_size, x_train)\n",
    "            batch_cost, _ = sess.run([cost, opt], feed_dict={inputs_: img_batch,targets_: img_batch})\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                      \"Training loss: {:.4f}\".format(batch_cost))\n",
    "#     saver = tf.train.Saver()\n",
    "#     saver.save(sess, 'models/conv_ae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = decoded.eval({inputs_:x_test},session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.subplot(121)\n",
    "plt.imshow(x_test[100].reshape(64,64))\n",
    "plt.subplot(122)\n",
    "plt.imshow(pred[100].reshape(64,64))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_variables = encoded.eval({inputs_:x_test},session=sess)\n",
    "wd = dict(zip(names_test, latent_variables))\n",
    "df = pd.DataFrame.from_dict(wd, orient=\"index\")\n",
    "df.to_csv(\"test_latent.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
